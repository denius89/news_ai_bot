"""
Module: database.db_models
Purpose: Core database operations and Supabase client management (Legacy)
Location: database/db_models.py

Description:
    Legacy –º–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Supabase.
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è CRUD –æ–ø–µ—Ä–∞—Ü–∏–π —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏, —Å–æ–±—ã—Ç–∏—è–º–∏,
    –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏, –¥–∞–π–¥–∂–µ—Å—Ç–∞–º–∏ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π.

    ‚ö†Ô∏è –í–ê–ñ–ù–û: –≠—Ç–æ legacy –º–æ–¥—É–ª—å. –î–ª—è –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ database.service

Key Components:
    - supabase: –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π Supabase –∫–ª–∏–µ–Ω—Ç
    - safe_execute(): Retry wrapper –¥–ª—è database queries
    - News operations: upsert_news(), get_latest_news()
    - Events operations: upsert_event(), get_latest_events()
    - User management: upsert_user_by_telegram(), get_user_by_telegram()
    - Digest operations: save_digest(), get_user_digests()
    - Analytics: log_digest_generation(), get_digest_analytics()

Dependencies:
    External:
        - supabase-py: Supabase Python client
        - python-dotenv: Environment variables
    Internal:
        - ai_modules.credibility: Credibility scoring
        - ai_modules.importance: Importance scoring
        - config.core.settings: Configuration
        - utils.system.dates: Date utilities

Usage Example:
    ```python
    from database.db_models import get_latest_news, upsert_news

    # –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
    news = get_latest_news(categories=["tech", "crypto"], limit=10)

    # –í—Å—Ç–∞–≤–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏
    news_items = [{"title": "...", "content": "...", ...}]
    upsert_news(news_items)
    ```

Migration Path:
    –°—Ç–∞—Ä—ã–π –∫–æ–¥ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —ç—Ç–æ—Ç –º–æ–¥—É–ª—å (22 —Ñ–∞–π–ª–∞ –∑–∞–≤–∏—Å—è—Ç –æ—Ç –Ω–µ–≥–æ).
    –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –º–∏–≥—Ä–∏—Ä—É–µ–º –Ω–∞ database.service:

    ```python
    # –°—Ç–∞—Ä—ã–π —Å–ø–æ—Å–æ–± (db_models):
    from database.db_models import get_latest_news
    news = get_latest_news(limit=10)

    # –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–± (service):
    from database.service import get_sync_service
    db_service = get_sync_service()
    news = db_service.get_latest_news(limit=10)
    ```

Notes:
    - –ó–∞–≥—Ä—É–∂–∞–µ—Ç .env –∏–∑ config_files/.env (–Ω–µ –∏–∑ settings!)
    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (global supabase client)
    - –°–º–µ—à–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ –¥–æ–º–µ–Ω—ã (news, events, users, digests)
    - HTTP/2 –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è pseudo-header errors
    - –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –∫–æ–¥–∞

Author: PulseAI Team
Last Updated: October 2025
"""

import hashlib
import logging
import os
import time
from datetime import datetime, timezone, timedelta
from typing import List, Dict, Optional, Union
from supabase import create_client, Client

from ai_modules.credibility import evaluate_credibility
from ai_modules.importance import evaluate_importance
from config.core.settings import COUNTRY_MAP, SUPABASE_URL, SUPABASE_KEY
from utils.system.dates import format_datetime, ensure_utc_iso

# --- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ---
logger = logging.getLogger("database")

supabase: Optional[Client] = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º HTTP/2 –¥–ª—è —Ä–µ—à–µ–Ω–∏—è pseudo-header –æ—à–∏–±–∫–∏
        os.environ["HTTPX_NO_HTTP2"] = "1"
        os.environ["SUPABASE_HTTP2_DISABLED"] = "1"

        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω—ã–º HTTP/2
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        logger.info("‚úÖ Supabase client initialized with HTTP/2 disabled via environment")
    except Exception as e:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Supabase: %s", e)
else:
    logger.warning("‚ö†Ô∏è Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–Ω–µ—Ç –∫–ª—é—á–µ–π). Unit-—Ç–µ—Å—Ç—ã –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –±–µ–∑ –ë–î.")


# --- SAFE EXECUTE (—Ä–µ—Ç—Ä–∞–∏) ---
def safe_execute(query, retries: int = 5, delay: float = 1.0):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö Supabase/httpx.
    –£–≤–µ–ª–∏—á–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∞ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞.
    """
    for attempt in range(1, retries + 1):
        try:
            logger.info(f"üîç Database query attempt {attempt}/{retries}")
            result = query.execute()
            logger.info(f"‚úÖ Database query successful on attempt {attempt}")
            return result
        except Exception as e:
            error_str = str(e)
            if "ConnectionTerminated" in error_str or "error_code:9" in error_str:
                logger.warning(f"‚ö†Ô∏è HTTP/2 connection error attempt {attempt}/{retries}: {e}")
            else:
                logger.warning(f"‚ö†Ô∏è Database error attempt {attempt}/{retries}: {e}")

            if attempt < retries:
                # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: 1s, 2s, 4s, 8s
                wait_time = delay * (2 ** (attempt - 1))
                logger.info(f"‚è≥ Waiting {wait_time}s before retry...")
                time.sleep(wait_time)
            else:
                logger.error(f"‚ùå Query failed after {retries} attempts: {e}")
                raise


# --- UID –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π ---
def make_uid(url: str, title: str) -> str:
    return hashlib.sha256(f"{url}|{title}".encode()).hexdigest()


# --- Event ID –¥–ª—è —Å–æ–±—ã—Ç–∏–π ---
def make_event_id(title: str, country: str, event_time: str) -> str:
    raw = f"{title}|{country}|{event_time}"
    return hashlib.sha256(raw.encode()).hexdigest()


# --- –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç ---
def parse_datetime_from_row(
    value: Union[str, datetime, None],
) -> Optional[datetime]:
    """
    –ü–∞—Ä—Å–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –¥–∞—Ç—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ë–î –≤ datetime –æ–±—ä–µ–∫—Ç.

    Args:
        value: –ó–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ë–î (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ datetime)

    Returns:
        datetime –æ–±—ä–µ–∫—Ç –∏–ª–∏ None
    """
    if value is None:
        return None

    if isinstance(value, datetime):
        return value

    if isinstance(value, str):
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º ISO —Ñ–æ—Ä–º–∞—Ç
            if "T" in value or "+" in value or value.endswith("Z"):
                return datetime.fromisoformat(value.replace("Z", "+00:00"))
            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
            elif len(value) == 10 and value.count("-") == 2:
                return datetime.fromisoformat(value + "T00:00:00+00:00")
            # Fallback –∫ —Ç–µ–∫—É—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É: {value}")
                return datetime.now(timezone.utc)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{value}': {e}")
            return datetime.now(timezone.utc)

    return None


# --- –û–±–æ–≥–∞—â–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π AI ---
def enrich_news_with_ai(news_item: Dict) -> Dict:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç credibility –∏ importance –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ AI-–º–æ–¥—É–ª–∏."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ news_item - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
    if not isinstance(news_item, dict):
        logger.error(f"enrich_news_with_ai –ø–æ–ª—É—á–∏–ª –Ω–µ —Å–ª–æ–≤–∞—Ä—å: {type(news_item)} = {news_item}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π –æ–±—ä–µ–∫—Ç –∫–∞–∫ —Å–ª–æ–≤–∞—Ä—å
        if isinstance(news_item, str):
            return {
                "content": news_item,
                "credibility": 0.5,
                "importance": 0.5,
            }
        return {"credibility": 0.5, "importance": 0.5}

    try:
        news_item["credibility"] = evaluate_credibility(news_item)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ AI-–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ credibility: {e}")
        news_item["credibility"] = 0.5

    try:
        news_item["importance"] = evaluate_importance(news_item)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ AI-–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ importance: {e}")
        news_item["importance"] = 0.5

    return news_item


# --- UPSERT –Ω–æ–≤–æ—Å—Ç–µ–π ---
def upsert_news(items: List[Dict]):
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ Supabase –±–µ–∑ –¥—É–±–ª–µ–π (–ø–æ uid) –∏ —Å –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º AI."""
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        return

    rows: List[Dict] = []
    for item in items:
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ item - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å
            if not isinstance(item, dict):
                logger.error(f"upsert_news –ø–æ–ª—É—á–∏–ª –Ω–µ —Å–ª–æ–≤–∞—Ä—å: {type(item)} = {item}")
                continue

            enriched = enrich_news_with_ai(item)

            title = (enriched.get("title") or "").strip() or enriched.get("source") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            content = (enriched.get("content") or "").strip() or (enriched.get("summary") or "").strip() or title
            uid = make_uid(enriched.get("url", ""), title)

            row = {
                "uid": uid,
                "title": title[:512],
                "content": content,
                "link": enriched.get("url"),
                "published_at": ensure_utc_iso(enriched.get("published_at")) or datetime.now(timezone.utc).isoformat(),
                "source": enriched.get("source"),
                "category": (enriched.get("category") or "").lower() or None,
                "credibility": enriched.get("credibility"),
                "importance": enriched.get("importance"),
            }
            logger.debug("Prepared news row: %s", row)
            rows.append(row)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: %s, item=%s", e, item)

    if not rows:
        logger.info("–ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏")
        return

    try:
        res = safe_execute(supabase.table("news").upsert(rows, on_conflict="uid"))
        inserted = len(res.data or [])
        logger.info(
            "‚úÖ Upsert news: %s prepared, %s inserted/updated",
            len(rows),
            inserted,
        )
        return res
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Supabase: %s", e)


# --- UPSERT —Å–æ–±—ã—Ç–∏–π ---
def upsert_event(items: List[Dict]):
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏—è –≤ Supabase –±–µ–∑ –¥—É–±–ª–µ–π (–ø–æ event_id)."""
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, —Å–æ–±—ã—Ç–∏—è –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        return

    rows: List[Dict] = []
    for item in items:
        try:
            event_time = item.get("datetime")
            if isinstance(event_time, datetime):
                event_time = ensure_utc_iso(event_time)
            elif not event_time:
                event_time = datetime.now(timezone.utc).isoformat()

            country_raw = (item.get("country") or "").lower()
            country_code = COUNTRY_MAP.get(country_raw)
            event_id = make_event_id(item.get("title", ""), item.get("country", ""), event_time)

            row = {
                "event_id": event_id,
                "event_time": event_time,
                "country": item.get("country"),
                "currency": item.get("currency"),
                "title": item.get("title"),
                "importance": item.get("importance"),
                "priority": item.get("priority"),
                "fact": item.get("fact"),
                "forecast": item.get("forecast"),
                "previous": item.get("previous"),
                "source": item.get("source", "investing"),
                "country_code": country_code,
                "created_at": datetime.now(timezone.utc).isoformat(),
            }
            logger.debug("Prepared event row: %s", row)
            rows.append(row)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–æ–±—ã—Ç–∏—è: %s, item=%s", e, item)

    if not rows:
        logger.info("–ù–µ—Ç —Å–æ–±—ã—Ç–∏–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏")
        return

    try:
        res = safe_execute(supabase.table("events").upsert(rows, on_conflict="event_id"))
        inserted = len(res.data or [])
        logger.info(
            "‚úÖ Upsert events: %s prepared, %s inserted/updated",
            len(rows),
            inserted,
        )
        return res
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ —Å–æ–±—ã—Ç–∏–π –≤ Supabase: %s", e)


# üëâ –ê–ª–∏–∞—Å
upsert_events = upsert_event


# --- –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π ---
def get_latest_events(limit: int = 10) -> List[Dict]:
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, get_latest_events –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.")
        return []

    query = (
        supabase.table("events")
        .select("event_time, country, country_code, currency, title, importance, fact, forecast, previous, source")
        .order("event_time", desc=False)
        .limit(limit)
    )

    try:
        data = safe_execute(query).data or []
        logger.debug("get_latest_events: fetched %d rows", len(data))
        for ev in data:
            ev["event_time_fmt"] = format_datetime(ev.get("event_time"))
            try:
                ev["importance"] = int(ev.get("importance") or 0)
            except Exception:
                ev["importance"] = 0
        return data
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–±—ã—Ç–∏–π: %s", e)
        return []


# --- –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π ---
def get_latest_news(
    source: Optional[str] = None,
    categories: Optional[List[str]] = None,
    limit: int = 10,
) -> List[Dict]:
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, get_latest_news –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.")
        return []

    logger.debug(
        "get_latest_news: source=%s, categories=%s, limit=%s",
        source,
        categories,
        limit,
    )

    query = (
        supabase.table("news")
        .select("id, uid, title, content, link, published_at, source, category, subcategory, credibility, importance")
        .order("published_at", desc=True)
        .limit(limit)
    )

    if source:
        query = query.eq("source", source)
    if categories:
        cats = [c.lower() for c in categories]
        query = query.in_("category", cats)

    try:
        data = safe_execute(query).data or []
        logger.debug("get_latest_news: fetched %d rows", len(data))
        for row in data:
            # –ü–∞—Ä—Å–∏–º published_at –≤ datetime –æ–±—ä–µ–∫—Ç
            row["published_at"] = parse_datetime_from_row(row.get("published_at"))
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            row["published_at_fmt"] = format_datetime(row.get("published_at"))
        return data
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: %s", e)
        return []


# --- USER MANAGEMENT FUNCTIONS ---


def upsert_user_by_telegram(
    telegram_id: int,
    username: str | None = None,
    locale: str = "ru",
    first_name: str | None = None,
) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ Telegram ID.

    Args:
        telegram_id: Telegram user ID
        username: Telegram username (optional)
        locale: User locale (default: 'ru')
        first_name: User first name (optional)

    Returns:
        User ID from database
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return ""

    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∏–º—ë–Ω
        from utils.text.name_normalizer import normalize_user_name

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        normalized_first_name = normalize_user_name(first_name, username, telegram_id)

        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        existing_user = supabase.table("users").select("*").eq("telegram_id", telegram_id).execute()

        if existing_user.data:
            user_data = existing_user.data[0]
            user_id = user_data["id"]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            update_data = {}
            if normalized_first_name and not user_data.get("first_name"):
                update_data["first_name"] = normalized_first_name
            if username and not user_data.get("username"):
                update_data["username"] = username

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if update_data:
                update_data["updated_at"] = "now()"
                supabase.table("users").update(update_data).eq("id", user_id).execute()
                logger.info(
                    "–û–±–Ω–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ID=%s, –¥–∞–Ω–Ω—ã–µ=%s",
                    user_id,
                    update_data,
                )

            logger.debug("–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: ID=%s", user_id)
            return user_id

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º
        new_user_data = {
            "telegram_id": telegram_id,
            "username": username,
            "locale": locale,
            "first_name": normalized_first_name,
        }

        new_user = supabase.table("users").insert(new_user_data).execute()

        if new_user.data:
            user_id = new_user.data[0]["id"]
            logger.info(
                "–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: ID=%s, telegram_id=%d, first_name=%s",
                user_id,
                telegram_id,
                first_name,
            )
            return user_id
        else:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            return ""

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏/–ø–æ–∏—Å–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %s", e)
        return ""


def get_user_by_telegram(telegram_id: int) -> dict | None:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ Telegram ID.

    Args:
        telegram_id: Telegram user ID

    Returns:
        User data dict or None if not found
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return None

    try:
        result = supabase.table("users").select("*").eq("telegram_id", telegram_id).execute()

        if result.data:
            return result.data[0]
        return None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %s", e)
        return None


def add_subscription(user_id: str, category: str) -> bool:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID
        category: News category

    Returns:
        True if subscription was added, False if already exists
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        result = supabase.table("subscriptions").insert({"user_id": user_id, "category": category}).execute()

        if result.data:
            logger.info(
                "–î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–æ–¥–ø–∏—Å–∫–∞: user_id=%d, category=%s",
                user_id,
                category,
            )
            return True
        else:
            logger.debug(
                "–ü–æ–¥–ø–∏—Å–∫–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: user_id=%d, category=%s",
                user_id,
                category,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–¥–ø–∏—Å–∫–∏: %s", e)
        return False


def remove_subscription(user_id: str, category: str) -> int:
    """
    –£–¥–∞–ª—è–µ—Ç –ø–æ–¥–ø–∏—Å–∫—É –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID
        category: News category

    Returns:
        Number of deleted subscriptions (0 or 1)
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return 0

    try:
        result = supabase.table("subscriptions").delete().eq("user_id", user_id).eq("category", category).execute()

        deleted_count = len(result.data) if result.data else 0
        if deleted_count > 0:
            logger.info("–£–¥–∞–ª–µ–Ω–∞ –ø–æ–¥–ø–∏—Å–∫–∞: user_id=%d, category=%s", user_id, category)

        return deleted_count

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø–æ–¥–ø–∏—Å–∫–∏: %s", e)
        return 0


def list_subscriptions(user_id: str) -> list[dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–¥–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID

    Returns:
        List of subscription dicts
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        result = supabase.table("subscriptions").select("*").eq("user_id", user_id).execute()

        return result.data or []

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ–¥–ø–∏—Å–æ–∫: %s", e)
        return []


def upsert_notification(
    user_id: str,
    type_: str = "digest",
    frequency: str = "daily",
    enabled: bool = True,
    preferred_hour: int = 9,
) -> None:
    """
    –°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID
        type_: Notification type ('digest', 'events', 'breaking')
        frequency: Notification frequency ('daily', 'weekly', 'instant')
        enabled: Whether notification is enabled
        preferred_hour: Preferred hour for daily notifications (0-23)
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        # –£–∫–∞–∑—ã–≤–∞–µ–º on_conflict –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ (user_id, type)
        result = (
            supabase.table("notifications")
            .upsert(
                {
                    "user_id": user_id,
                    "type": type_,
                    "frequency": frequency,
                    "enabled": enabled,
                    "preferred_hour": preferred_hour,
                },
                on_conflict="user_id,type",  # –£–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
            )
            .execute()
        )

        if result.data:
            logger.info(
                "–û–±–Ω–æ–≤–ª–µ–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: user_id=%s, type=%s",
                user_id,
                type_,
            )

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: %s", e)


def list_notifications(user_id: str) -> list[dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID

    Returns:
        List of notification settings dicts
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        result = supabase.table("notifications").select("*").eq("user_id", user_id).execute()

        return result.data or []

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: %s", e)
        return []


# --- USER NOTIFICATIONS FUNCTIONS ---


def get_user_notifications(user_id: Union[int, str], limit: int = 50, offset: int = 0) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID
        limit: Maximum number of notifications to return
        offset: Number of notifications to skip

    Returns:
        List of notification dicts
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        result = (
            supabase.table("user_notifications")
            .select("id, title, message, read, user_id")
            .eq("user_id", user_id)
            .order("id", desc=True)  # Use id instead of created_at
            .limit(limit)
            .execute()
        )

        notifications = result.data or []
        logger.info(
            "–ü–æ–ª—É—á–µ–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: %d –¥–ª—è user_id=%s",
            len(notifications),
            user_id,
        )
        return notifications

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: %s", e)
        return []


def create_user(
    telegram_id: int,
    username: str = None,
    locale: str = "ru",
    first_name: str = None,
) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.

    Args:
        telegram_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ Telegram
        username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        locale: –õ–æ–∫–∞–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'ru')
        first_name: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

    Returns:
        UUID –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return ""

    try:
        import uuid

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π UUID –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        new_user_id = str(uuid.uuid4())

        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        result = (
            supabase.table("users")
            .insert(
                {
                    "id": new_user_id,
                    "telegram_id": telegram_id,
                    "username": username,
                    "locale": locale,
                    "first_name": first_name,
                    "created_at": "now()",
                    "updated_at": "now()",
                }
            )
            .execute()
        )

        if result.data:
            logger.info(
                f"–ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–æ–∑–¥–∞–Ω: ID={new_user_id}, telegram_id={telegram_id}, first_name={first_name}"
            )
            return new_user_id
        else:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            return ""

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
        return ""


def create_user_notification(
    user_id: Union[int, str],
    title: str,
    content: str,
    category: str = "general",
    read: bool = False,
    via_telegram: bool = False,
    via_webapp: bool = True,
) -> Optional[str]:
    """
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID
        title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        read: –ü—Ä–æ—á–∏—Ç–∞–Ω–æ –ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        via_telegram: –û—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏ —á–µ—Ä–µ–∑ Telegram
        via_webapp: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≤ WebApp

    Returns:
        ID —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return None

    try:
        notification_data = {
            "user_id": str(user_id),
            "title": title,
            "message": content,  # –í –±–∞–∑–µ –ø–æ–ª–µ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è message
            "category": category,
            "read": read,
            "via_telegram": via_telegram,
            "via_webapp": via_webapp,
        }

        result = supabase.table("user_notifications").insert(notification_data).execute()

        if result.data and len(result.data) > 0:
            notification_id = result.data[0].get("id")
            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ: user_id={user_id}, notification_id={notification_id}")
            return str(notification_id)
        else:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è user_id={user_id}")
            return None

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è: {e}")
        return None


def mark_notification_read(user_id: Union[int, str], notification_id: Union[int, str]) -> bool:
    """
    –û—Ç–º–µ—á–∞–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ.

    Args:
        user_id: User ID
        notification_id: Notification ID

    Returns:
        True if notification was marked as read, False otherwise
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        logger.info(
            "Marking notification as read: user_id=%s, notification_id=%s",
            user_id,
            notification_id,
        )
        result = (
            supabase.table("user_notifications")
            .update({"read": True})
            .eq("id", notification_id)
            .eq("user_id", user_id)  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            .execute()
        )
        logger.info("Update result: %s", result.data)

        if result.data and len(result.data) > 0:
            logger.info(
                "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–º–µ—á–µ–Ω–æ –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ: user_id=%s, notification_id=%s",
                user_id,
                notification_id,
            )
            return True
        else:
            logger.warning(
                "–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: user_id=%s, notification_id=%s",
                user_id,
                notification_id,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–º–µ—Ç–∫–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–≥–æ: %s", e)
        return False


# --- DIGEST FUNCTIONS ---


def save_digest(
    user_id: str,
    summary: str,
    category: str = "all",
    style: str = "analytical",
    period: str = "today",
    limit_count: int = 10,
    metadata: dict = None,
) -> str:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        summary: –¢–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞
        category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π (crypto, sports, markets, tech, world, all)
        style: –°—Ç–∏–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (analytical, business, meme)
        period: –ü–µ—Ä–∏–æ–¥ (today, 7d, 30d)
        limit_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ
        metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ

    Returns:
        ID —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return ""

    try:
        # –ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –Ω–æ–≤—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        digest_data = {
            "user_id": str(user_id),
            "summary": summary,
            "category": category,
            "style": style,
            "period": period,
            "limit_count": limit_count,
            "deleted_at": None,
            "archived": False,
            "metadata": metadata or {},
        }

        result = supabase.table("digests").insert(digest_data).execute()

        if result.data:
            digest_id = result.data[0]["id"]
            logger.info(
                "–î–∞–π–¥–∂–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: ID=%s, user_id=%s, category=%s, style=%s",
                digest_id,
                user_id,
                category,
                style,
            )
            return digest_id
        else:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–π–¥–∂–µ—Å—Ç")
            return ""

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return ""


def get_user_digests(
    user_id: str,
    limit: int = 20,
    offset: int = 0,
    include_deleted: bool = False,
    include_archived: bool = False,
) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º—è–≥–∫–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è.
    –ü–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –Ω–æ–≤—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤
        offset: –°–º–µ—â–µ–Ω–∏–µ –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        include_deleted: –í–∫–ª—é—á–∞—Ç—å –ª–∏ —É–¥–∞–ª–µ–Ω–Ω—ã–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã
        include_archived: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã

    Returns:
        –°–ø–∏—Å–æ–∫ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        query = supabase.table("digests").select("*").eq("user_id", user_id)

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å—Ç–∞—Ç—É—Å—É —Å –Ω–æ–≤—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        if include_deleted and include_archived:
            # –í—Å–µ –¥–∞–π–¥–∂–µ—Å—Ç—ã (–≤–∫–ª—é—á–∞—è —É–¥–∞–ª–µ–Ω–Ω—ã–µ –∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            pass
        elif include_deleted and not include_archived:
            # –¢–æ–ª—å–∫–æ —É–¥–∞–ª–µ–Ω–Ω—ã–µ (–Ω–µ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            query = query.not_.is_("deleted_at", "null")  # deleted = TRUE
            query = query.eq("archived", False)
        elif not include_deleted and include_archived:
            # –¢–æ–ª—å–∫–æ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ (–Ω–µ —É–¥–∞–ª–µ–Ω–Ω—ã–µ)
            query = query.is_("deleted_at", "null")  # deleted = FALSE
            query = query.eq("archived", True)
        else:  # not include_deleted and not include_archived
            # –¢–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ (–Ω–µ —É–¥–∞–ª–µ–Ω–Ω—ã–µ –∏ –Ω–µ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
            query = query.is_("deleted_at", "null")  # deleted = FALSE
            query = query.eq("archived", False)

        result = query.order("created_at", desc=True).range(offset, offset + limit - 1).execute()

        return result.data or []

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: %s", e)
        return []


def get_digest_by_id(digest_id: str, user_id: str = None) -> Dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ ID.

    Args:
        digest_id: ID –¥–∞–π–¥–∂–µ—Å—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏)

    Returns:
        –î–∞–Ω–Ω—ã–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return None

    try:
        query = supabase.table("digests").select("*").eq("id", digest_id)

        if user_id:
            query = query.eq("user_id", user_id)

        result = query.execute()

        if result.data:
            return result.data[0]
        else:
            logger.warning("–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: ID=%s", digest_id)
            return None

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return None


def soft_delete_digest(digest_id: str, user_id: str) -> bool:
    """
    –ú—è–≥–∫–æ —É–¥–∞–ª—è–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç deleted_at).

    Args:
        digest_id: ID –¥–∞–π–¥–∂–µ—Å—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        True –µ—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç —É–¥–∞–ª–µ–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        from datetime import datetime

        result = (
            supabase.table("digests")
            .update({"deleted_at": datetime.utcnow().isoformat()})
            .eq("id", digest_id)
            .eq("user_id", user_id)
            .is_("deleted_at", "null")  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—â–µ –Ω–µ —É–¥–∞–ª–µ–Ω
            .execute()
        )

        if result.data:
            logger.info("–î–∞–π–¥–∂–µ—Å—Ç –º—è–≥–∫–æ —É–¥–∞–ª–µ–Ω: ID=%s, user_id=%s", digest_id, user_id)
            return True
        else:
            logger.warning(
                "–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–ª–∏ —É–∂–µ —É–¥–∞–ª–µ–Ω: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –º—è–≥–∫–æ–º —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return False


def restore_digest(digest_id: str, user_id: str) -> bool:
    """
    –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –º—è–≥–∫–æ —É–¥–∞–ª–µ–Ω–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç.

    Args:
        digest_id: ID –¥–∞–π–¥–∂–µ—Å—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        True –µ—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        result = (
            supabase.table("digests")
            .update(
                {
                    "deleted_at": None,
                    "archived": False,  # –¢–∞–∫–∂–µ —É–±–∏—Ä–∞–µ–º –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏
                }
            )
            .eq("id", digest_id)
            .eq("user_id", user_id)
            .not_.is_("deleted_at", "null")  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω (deleted_at IS NOT NULL)
            .execute()
        )

        if result.data:
            logger.info("–î–∞–π–¥–∂–µ—Å—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: ID=%s, user_id=%s", digest_id, user_id)
            return True
        else:
            logger.warning(
                "–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–ª–∏ –Ω–µ —É–¥–∞–ª–µ–Ω: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return False


def archive_digest(digest_id: str, user_id: str) -> bool:
    """
    –ê—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        digest_id: ID –¥–∞–π–¥–∂–µ—Å—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        True –µ—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        result = (
            supabase.table("digests")
            .update({"archived": True})
            .eq("id", digest_id)
            .eq("user_id", user_id)
            .eq("archived", False)  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω
            .is_("deleted_at", "null")  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–µ–Ω
            .execute()
        )

        if result.data:
            logger.info("–î–∞–π–¥–∂–µ—Å—Ç –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω: ID=%s, user_id=%s", digest_id, user_id)
            return True
        else:
            logger.warning(
                "–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —É–∂–µ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω –∏–ª–∏ —É–¥–∞–ª–µ–Ω: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return False


def unarchive_digest(digest_id: str, user_id: str) -> bool:
    """
    –†–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä—É–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        digest_id: ID –¥–∞–π–¥–∂–µ—Å—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        True –µ—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç —Ä–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        result = (
            supabase.table("digests")
            .update(
                {
                    "archived": False,
                    "deleted_at": None,  # –¢–∞–∫–∂–µ —É–±–∏—Ä–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏ —Ä–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏
                }
            )
            .eq("id", digest_id)
            .eq("user_id", user_id)
            .eq("archived", True)  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω
            .execute()
        )

        if result.data:
            logger.info(
                "–î–∞–π–¥–∂–µ—Å—Ç —Ä–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return True
        else:
            logger.warning(
                "–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–ª–∏ –Ω–µ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return False


def permanent_delete_digest(digest_id: str, user_id: str) -> bool:
    """
    –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ).

    Args:
        digest_id: ID –¥–∞–π–¥–∂–µ—Å—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        True –µ—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç —É–¥–∞–ª–µ–Ω, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        result = supabase.table("digests").delete().eq("id", digest_id).eq("user_id", user_id).execute()

        if result.data:
            logger.info(
                "–î–∞–π–¥–∂–µ—Å—Ç –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª–µ–Ω: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return True
        else:
            logger.warning(
                "–î–∞–π–¥–∂–µ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: ID=%s, user_id=%s",
                digest_id,
                user_id,
            )
            return False

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–º —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞: %s", e)
        return False


# =============================================================================
# USER PREFERENCES FUNCTIONS
# =============================================================================


def save_user_preferences(
    user_id: str,
    preferred_category: str = "all",
    preferred_style: str = "analytical",
    preferred_period: str = "today",
    min_importance: float = 0.3,
    enable_smart_filtering: bool = True,
) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        preferred_category: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
        preferred_style: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —Å—Ç–∏–ª—å
        preferred_period: –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –ø–µ—Ä–∏–æ–¥
        min_importance: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π
        enable_smart_filtering: –í–∫–ª—é—á–∏—Ç—å —É–º–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        preferences_data = {
            "user_id": user_id,
            "preferred_category": preferred_category,
            "preferred_style": preferred_style,
            "preferred_period": preferred_period,
            "min_importance": min_importance,
            "enable_smart_filtering": enable_smart_filtering,
            "last_used_at": datetime.now(timezone.utc).isoformat(),
        }

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
        supabase.table("user_preferences").upsert(preferences_data, on_conflict="user_id").execute()

        logger.info(f"–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        return True

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return False


def get_user_preferences(user_id: str) -> Dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return _get_default_preferences()

    try:
        result = supabase.table("user_preferences").select("*").eq("user_id", user_id).execute()

        if result.data:
            preferences = result.data[0]
            logger.debug(f"–ù–∞–π–¥–µ–Ω—ã –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return preferences
        else:
            logger.debug(f"–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return _get_default_preferences()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return _get_default_preferences()


def _get_default_preferences() -> Dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
    return {
        "preferred_category": "all",
        "preferred_style": "analytical",
        "preferred_period": "today",
        "min_importance": 0.3,
        "enable_smart_filtering": True,
    }


# =============================================================================
# ANALYTICS FUNCTIONS
# =============================================================================


def log_digest_generation(
    user_id: str,
    category: str,
    style: str,
    period: str,
    min_importance: float = None,
    generation_time_ms: int = None,
    success: bool = True,
    error_message: str = None,
    news_count: int = 0,
) -> bool:
    """
    –õ–æ–≥–∏—Ä—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–∞–π–¥–∂–µ—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –¥–∞–π–¥–∂–µ—Å—Ç–∞
        style: –°—Ç–∏–ª—å –¥–∞–π–¥–∂–µ—Å—Ç–∞
        period: –ü–µ—Ä–∏–æ–¥ –¥–∞–π–¥–∂–µ—Å—Ç–∞
        min_importance: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å
        generation_time_ms: –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
        success: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        error_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        news_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∞–π–¥–∂–µ—Å—Ç–µ

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–æ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        analytics_data = {
            "user_id": user_id,
            "category": category,
            "style": style,
            "period": period,
            "min_importance": min_importance,
            "generation_time_ms": generation_time_ms,
            "success": success,
            "error_message": error_message,
            "news_count": news_count,
            "created_at": datetime.now(timezone.utc).isoformat(),
        }

        result = safe_execute(supabase.table("digest_analytics").insert(analytics_data))

        if result.data:
            logger.debug(f"–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return True
        else:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return False

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return False


def get_digest_analytics(user_id: str = None, days: int = 30) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤.

    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        –°–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        # –í—ã—á–∏—Å–ª—è–µ–º –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞
        start_date = datetime.now(timezone.utc) - timedelta(days=days)

        query = supabase.table("digest_analytics").select("*").gte("created_at", start_date.isoformat())

        if user_id:
            query = query.eq("user_id", user_id)

        result = safe_execute(query.order("created_at", desc=True))

        return result.data or []

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
        return []


# =============================================================================
# SMART FILTERING FUNCTIONS
# =============================================================================


def get_latest_news_with_importance(
    source: str = None,
    categories: List[str] = None,
    limit: int = 10,
    min_importance: float = None,
) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏.

    Args:
        source: –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
        categories: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π
        min_importance: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π

    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        query = (
            supabase.table("news")
            .select(
                "id, uid, title, content, link, published_at, source, category, subcategory, credibility, importance"
            )
            .order("published_at", desc=True)
            .limit(limit)
        )

        if source:
            query = query.eq("source", source)

        if categories:
            cats = [c.lower() for c in categories]
            query = query.in_("category", cats)

        if min_importance is not None:
            query = query.gte("importance", min_importance)

        result = query.execute()
        data = result.data or []

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞ min_importance)
        if min_importance is None:
            data = sorted(data, key=lambda x: x.get("importance", 0), reverse=True)

        logger.debug(f"–ü–æ–ª—É—á–µ–Ω–æ {len(data)} –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏")

        for row in data:
            # –ü–∞—Ä—Å–∏–º published_at –≤ datetime –æ–±—ä–µ–∫—Ç
            row["published_at"] = parse_datetime_from_row(row.get("published_at"))
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            row["published_at_fmt"] = format_datetime(row.get("published_at"))

        return data

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π: {e}")
        # Fallback –Ω–∞ —Å—Ç–∞—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é
        return get_latest_news(source, categories, limit)


def get_smart_filter_for_time() -> Dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–Ω—è.

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return _get_default_smart_filter()

    try:
        current_hour = datetime.now().hour
        current_weekday = datetime.now().weekday()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å–ª–æ–≤–∏–µ –≤—Ä–µ–º–µ–Ω–∏
        if current_weekday >= 5:  # –í—ã—Ö–æ–¥–Ω—ã–µ
            time_condition = "weekend"
        elif 6 <= current_hour < 12:  # –£—Ç—Ä–æ
            time_condition = "morning"
        elif 18 <= current_hour < 23:  # –í–µ—á–µ—Ä
            time_condition = "evening"
        else:
            time_condition = "all"

        result = (
            supabase.table("smart_filters")
            .select("*")
            .eq("time_condition", time_condition)
            .eq("is_active", True)
            .execute()
        )

        if result.data:
            filter_data = result.data[0]
            logger.debug(f"–ü—Ä–∏–º–µ–Ω–µ–Ω —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏: {time_condition}")
            return filter_data
        else:
            logger.debug(f"–£–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ {time_condition} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return _get_default_smart_filter()

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —É–º–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞: {e}")
        return _get_default_smart_filter()


def _get_default_smart_filter() -> Dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–º–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
    return {
        "min_importance": 0.3,
        "max_items": 10,
        "categories": None,
        "time_condition": "all",
    }


# =========================
# DIGEST METRICS FUNCTIONS
# =========================


def save_digest_with_metrics(
    user_id: str,
    summary: str,
    category: str,
    style: str,
    confidence: float,
    generation_time_sec: float,
    meta: dict,
    skipped_reason: Optional[str] = None,
) -> str:
    """
    Save digest with metrics to database.

    Args:
        user_id: User ID
        summary: Digest content
        category: News category
        style: AI style (analytical, business, meme)
        confidence: AI confidence score (0.0-1.0)
        generation_time_sec: Time taken to generate digest
        meta: Additional metadata (style_profile, tone, length, audience)
        skipped_reason: Reason why digest was skipped (if any)

    Returns:
        Digest ID
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return None

    try:
        digest_data = {
            "user_id": user_id,
            "summary": summary,
            "category": category,
            "style": style,
            "confidence": confidence,
            "generation_time_sec": generation_time_sec,
            "meta": meta,
            "skipped_reason": skipped_reason,
            "created_at": datetime.now(timezone.utc).isoformat(),
        }

        result = safe_execute(supabase.table("digests").insert(digest_data))

        if result.data:
            digest_id = result.data[0]["id"]
            logger.info(f"‚úÖ Digest saved with metrics: {digest_id}")

            # Update daily analytics
            # update_daily_analytics() - deprecated, using individual event logging

            return digest_id
        else:
            logger.error("‚ùå Failed to save digest with metrics")
            return None

    except Exception as e:
        logger.error(f"‚ùå Error saving digest with metrics: {e}")
        return None


def update_digest_feedback(digest_id: str, score: float) -> bool:
    """
    Update feedback score for digest.

    Args:
        digest_id: Digest ID
        score: Feedback score (0.0-1.0)

    Returns:
        True if successful, False otherwise
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        # Get current digest data
        result = safe_execute(supabase.table("digests").select("feedback_score", "feedback_count").eq("id", digest_id))

        if not result.data:
            logger.warning(f"Digest {digest_id} not found")
            return False

        current_data = result.data[0]
        current_score = current_data.get("feedback_score", 0.0) or 0.0
        current_count = current_data.get("feedback_count", 0) or 0

        # Calculate new average
        if current_count == 0:
            new_score = score
        else:
            new_score = (current_score * current_count + score) / (current_count + 1)

        new_count = current_count + 1

        # Update digest
        update_result = safe_execute(
            supabase.table("digests")
            .update(
                {
                    "feedback_score": round(new_score, 3),
                    "feedback_count": new_count,
                }
            )
            .eq("id", digest_id)
        )

        if update_result.data:
            logger.info(f"‚úÖ Feedback updated for digest {digest_id}: {score} (avg: {new_score:.3f})")
            return True
        else:
            logger.error(f"‚ùå Failed to update feedback for digest {digest_id}")
            return False

    except Exception as e:
        logger.error(f"‚ùå Error updating digest feedback: {e}")
        return False


def get_daily_digest_analytics(date: Optional[str] = None) -> dict:
    """
    Get aggregated analytics for date (default: today).

    Args:
        date: Date in YYYY-MM-DD format (default: today)

    Returns:
        Dictionary with analytics data
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return {}

    try:
        if not date:
            date = datetime.now().strftime("%Y-%m-%d")

        # Try to get from digest_analytics table first (filter by created_at date)
        start_date = f"{date}T00:00:00Z"
        end_date = f"{date}T23:59:59Z"

        result = safe_execute(
            supabase.table("digest_analytics").select("*").gte("created_at", start_date).lte("created_at", end_date)
        )

        if result.data:
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –¥–µ–Ω—å
            records = result.data
            total_count = len(records)
            avg_generation_time = (
                sum(r.get("generation_time_ms", 0) for r in records) / total_count / 1000 if total_count > 0 else 0
            )
            success_count = sum(1 for r in records if r.get("success", False))

            logger.debug(f"‚úÖ Retrieved {total_count} analytics records from digest_analytics for {date}")
            return {
                "generated_count": total_count,
                "avg_confidence": 0.0,  # –ù–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π —Å—Ö–µ–º–µ
                "avg_generation_time_sec": avg_generation_time,
                "skipped_low_quality": total_count - success_count,
                "feedback_count": 0,  # –ù–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π —Å—Ö–µ–º–µ
                "avg_feedback_score": 0.0,  # –ù–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π —Å—Ö–µ–º–µ
            }

        # Fallback: calculate from digests table
        logger.debug(f"Calculating analytics from digests table for {date}")

        # Get digests for the date
        start_date = f"{date}T00:00:00Z"
        end_date = f"{date}T23:59:59Z"

        result = safe_execute(
            supabase.table("digests").select("*").gte("created_at", start_date).lte("created_at", end_date).execute()
        )

        if not result.data:
            return {
                "generated_count": 0,
                "avg_confidence": 0.0,
                "avg_generation_time_sec": 0.0,
                "skipped_low_quality": 0,
                "feedback_count": 0,
                "avg_feedback_score": 0.0,
            }

        digests = result.data

        # Calculate metrics
        generated_count = len(digests)
        skipped_low_quality = len([d for d in digests if d.get("skipped_reason")])

        # Confidence metrics
        confidences = [d.get("confidence") for d in digests if d.get("confidence") is not None]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

        # Generation time metrics
        times = [d.get("generation_time_sec") for d in digests if d.get("generation_time_sec") is not None]
        avg_generation_time_sec = sum(times) / len(times) if times else 0.0

        # Feedback metrics
        feedback_scores = [d.get("feedback_score") for d in digests if d.get("feedback_score") is not None]
        avg_feedback_score = sum(feedback_scores) / len(feedback_scores) if feedback_scores else 0.0
        feedback_count = sum(d.get("feedback_count", 0) for d in digests)

        analytics = {
            "generated_count": generated_count,
            "avg_confidence": round(avg_confidence, 3),
            "avg_generation_time_sec": round(avg_generation_time_sec, 2),
            "skipped_low_quality": skipped_low_quality,
            "feedback_count": feedback_count,
            "avg_feedback_score": round(avg_feedback_score, 3),
        }

        logger.debug(f"‚úÖ Calculated analytics for {date}: {analytics}")
        return analytics

    except Exception as e:
        logger.error(f"‚ùå Error getting digest analytics: {e}")
        return {}


def update_daily_analytics():
    """
    Update digest_analytics with today's aggregated data.
    Note: This function is deprecated as we now log individual digest generation events.
    """
    logger.warning("update_daily_analytics is deprecated - using individual event logging instead")
    return


def get_digest_analytics_history(days: int = 7) -> List[dict]:
    """
    Get digest analytics history for last N days.

    Args:
        days: Number of days to retrieve

    Returns:
        List of analytics data for each day
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return []

    try:
        # Get analytics for last N days
        result = safe_execute(
            supabase.table("digest_analytics").select("*").order("date", desc=True).limit(days).execute()
        )

        if result.data:
            logger.debug(f"‚úÖ Retrieved analytics history for {days} days")
            return result.data
        else:
            logger.debug(f"No analytics history found for {days} days")
            return []

    except Exception as e:
        logger.error(f"‚ùå Error getting analytics history: {e}")
        return []


# =============================================================================
# USER CATEGORY PREFERENCES FUNCTIONS (JSONB-based)
# =============================================================================


def get_user_category_preferences(user_id: str) -> Dict:
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ JSONB –ø–æ–ª—è.

    Args:
        user_id: User ID (UUID string)

    Returns:
        Dict —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π:
        {
            "sports": ["football", "basketball"],  # –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            "crypto": null,                         # –≤—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è
            "markets": [],                          # –æ—Ç–∫–ª—é—á–µ–Ω–∞
        }
        –ü—É—Å—Ç–æ–π dict {} –µ—Å–ª–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –Ω–µ—Ç
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return {}

    try:
        result = safe_execute(supabase.table("user_preferences").select("category_preferences").eq("user_id", user_id))

        if result.data and len(result.data) > 0:
            preferences = result.data[0].get("category_preferences", {})
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω—ã –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {preferences}")
            return preferences
        else:
            logger.debug(f"–ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π dict")
            return {}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return {}


def upsert_user_category_preferences(user_id: str, preferences: Dict) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        user_id: User ID (UUID string)
        preferences: Dict —Å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            {
                "sports": ["football"],
                "crypto": null,
                "markets": []
            }

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
    """
    if not supabase:
        logger.error("Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return False

    try:
        # Upsert preferences (—Å–æ–∑–¥–∞—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å)
        result = safe_execute(
            supabase.table("user_preferences").upsert(
                {
                    "user_id": user_id,
                    "category_preferences": preferences,
                    "updated_at": datetime.now(timezone.utc).isoformat(),
                },
                on_conflict="user_id",
            )
        )

        if result.data:
            logger.info(f"‚úÖ –ü—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return True
        else:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            return False

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        return False


def get_active_categories(user_id: str) -> Dict[str, List[str]]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

    –ü–∞—Ä—Å–∏—Ç JSONB —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ —Å–ø–∏—Å–∫–∞:
    - full_categories: –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å null (–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤—Å–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
    - subcategories: dict –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏

    Args:
        user_id: User ID (UUID string)

    Returns:
        Dict —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏:
        {
            'full_categories': ['crypto', 'tech'],  # null –≤ JSONB
            'subcategories': {
                'sports': ['football', 'basketball'],
                'markets': ['earnings']
            }
        }

    –õ–æ–≥–∏–∫–∞:
        - null = –≤–∫–ª—é—á–µ–Ω–∞ –≤—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º –≤ full_categories
        - ["sub1", "sub2"] = –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Üí –¥–æ–±–∞–≤–ª—è–µ–º –≤ subcategories
        - [] –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç = –æ—Ç–∫–ª—é—á–µ–Ω–∞ ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    """
    preferences = get_user_category_preferences(user_id)

    if not preferences:
        # –ï—Å–ª–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏
        # (–∑–Ω–∞—á–∏—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
        logger.debug(f"–ù–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è")
        return {"full_categories": [], "subcategories": {}}

    full_categories = []
    subcategories = {}

    for category, value in preferences.items():
        if value is None:
            # null = –≤—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –≤–∫–ª—é—á–µ–Ω–∞
            full_categories.append(category)
        elif isinstance(value, list) and len(value) > 0:
            # –°–ø–∏—Å–æ–∫ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π (–Ω–µ –ø—É—Å—Ç–æ–π)
            subcategories[category] = value
        # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ [] –∏–ª–∏ –¥—Ä—É–≥–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è = –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–æ—Ç–∫–ª—é—á–µ–Ω–∞)

    logger.debug(
        f"–ê–∫—Ç–∏–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: " f"full={full_categories}, subcategories={subcategories}"
    )

    return {"full_categories": full_categories, "subcategories": subcategories}
