import hashlib
import logging
import os
import time
from datetime import datetime, timezone
from typing import List, Dict, Optional, Union
from pathlib import Path
import httpx
from dotenv import load_dotenv
from supabase import create_client, Client

from ai_modules.credibility import evaluate_credibility
from ai_modules.importance import evaluate_importance
from config.settings import COUNTRY_MAP
from utils.dates import format_datetime, ensure_utc_iso

# --- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï ---
logger = logging.getLogger("database")

# --- –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ï –ö SUPABASE ---
load_dotenv(Path(__file__).resolve().parent.parent / ".env")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

supabase: Optional[Client] = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        logger.info("‚úÖ Supabase client initialized")
    except Exception as e:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Supabase: %s", e)
else:
    logger.warning(
        "‚ö†Ô∏è Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–Ω–µ—Ç –∫–ª—é—á–µ–π). Unit-—Ç–µ—Å—Ç—ã –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –±–µ–∑ –ë–î."
    )


# --- SAFE EXECUTE (—Ä–µ—Ç—Ä–∞–∏) ---
def safe_execute(query, retries: int = 3, delay: int = 2):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö Supabase/httpx.
    """
    for attempt in range(1, retries + 1):
        try:
            return query.execute()
        except (httpx.RemoteProtocolError, httpx.ConnectError) as e:
            logger.warning("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ %s/%s: –æ—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è %s", attempt, retries, e)
            if attempt < retries:
                time.sleep(delay)
            else:
                raise


# --- UID –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π ---
def make_uid(url: str, title: str) -> str:
    return hashlib.sha256(f"{url}|{title}".encode()).hexdigest()


# --- Event ID –¥–ª—è —Å–æ–±—ã—Ç–∏–π ---
def make_event_id(title: str, country: str, event_time: str) -> str:
    raw = f"{title}|{country}|{event_time}"
    return hashlib.sha256(raw.encode()).hexdigest()


# --- –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç ---
def parse_datetime_from_row(value: Union[str, datetime, None]) -> Optional[datetime]:
    """
    –ü–∞—Ä—Å–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –¥–∞—Ç—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ë–î –≤ datetime –æ–±—ä–µ–∫—Ç.
    
    Args:
        value: –ó–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –ë–î (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ datetime)
        
    Returns:
        datetime –æ–±—ä–µ–∫—Ç –∏–ª–∏ None
    """
    if value is None:
        return None
    
    if isinstance(value, datetime):
        return value
    
    if isinstance(value, str):
        try:
            # –ü–æ–ø—Ä–æ–±—É–µ–º ISO —Ñ–æ—Ä–º–∞—Ç
            if 'T' in value or '+' in value or value.endswith('Z'):
                return datetime.fromisoformat(value.replace('Z', '+00:00'))
            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã
            elif len(value) == 10 and value.count('-') == 2:
                return datetime.fromisoformat(value + 'T00:00:00+00:00')
            # Fallback –∫ —Ç–µ–∫—É—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É: {value}")
                return datetime.now(timezone.utc)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{value}': {e}")
            return datetime.now(timezone.utc)
    
    return None


# --- –û–±–æ–≥–∞—â–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π AI ---
def enrich_news_with_ai(news_item: Dict) -> Dict:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç credibility –∏ importance –¥–ª—è –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ AI-–º–æ–¥—É–ª–∏."""
    try:
        news_item["credibility"] = evaluate_credibility(news_item)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ AI-–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ credibility: {e}")
        news_item["credibility"] = 0.5

    try:
        news_item["importance"] = evaluate_importance(news_item)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ AI-–∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ importance: {e}")
        news_item["importance"] = 0.5

    return news_item


# --- UPSERT –Ω–æ–≤–æ—Å—Ç–µ–π ---
def upsert_news(items: List[Dict]):
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ Supabase –±–µ–∑ –¥—É–±–ª–µ–π (–ø–æ uid) –∏ —Å –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º AI."""
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, –¥–∞–Ω–Ω—ã–µ –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        return

    rows: List[Dict] = []
    for item in items:
        try:
            enriched = enrich_news_with_ai(item)

            title = (
                (enriched.get("title") or "").strip() or enriched.get("source") or "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
            )
            content = (
                (enriched.get("content") or "").strip()
                or (enriched.get("summary") or "").strip()
                or title
            )
            uid = make_uid(enriched.get("url", ""), title)

            row = {
                "uid": uid,
                "title": title[:512],
                "content": content,
                "link": enriched.get("url"),
                "published_at": ensure_utc_iso(enriched.get("published_at"))
                or datetime.now(timezone.utc).isoformat(),
                "source": enriched.get("source"),
                "category": (enriched.get("category") or "").lower() or None,
                "credibility": enriched.get("credibility"),
                "importance": enriched.get("importance"),
            }
            logger.debug("Prepared news row: %s", row)
            rows.append(row)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: %s, item=%s", e, item)

    if not rows:
        logger.info("–ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏")
        return

    try:
        res = safe_execute(supabase.table("news").upsert(rows, on_conflict="uid"))
        inserted = len(res.data or [])
        logger.info("‚úÖ Upsert news: %s prepared, %s inserted/updated", len(rows), inserted)
        return res
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Supabase: %s", e)


# --- UPSERT —Å–æ–±—ã—Ç–∏–π ---
def upsert_event(items: List[Dict]):
    """–í—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏—è –≤ Supabase –±–µ–∑ –¥—É–±–ª–µ–π (–ø–æ event_id)."""
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, —Å–æ–±—ã—Ç–∏—è –Ω–µ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        return

    rows: List[Dict] = []
    for item in items:
        try:
            event_time = item.get("datetime")
            if isinstance(event_time, datetime):
                event_time = ensure_utc_iso(event_time)
            elif not event_time:
                event_time = datetime.now(timezone.utc).isoformat()

            country_raw = (item.get("country") or "").lower()
            country_code = COUNTRY_MAP.get(country_raw)
            event_id = make_event_id(item.get("title", ""), item.get("country", ""), event_time)

            row = {
                "event_id": event_id,
                "event_time": event_time,
                "country": item.get("country"),
                "currency": item.get("currency"),
                "title": item.get("title"),
                "importance": item.get("importance"),
                "priority": item.get("priority"),
                "fact": item.get("fact"),
                "forecast": item.get("forecast"),
                "previous": item.get("previous"),
                "source": item.get("source", "investing"),
                "country_code": country_code,
                "created_at": datetime.now(timezone.utc).isoformat(),
            }
            logger.debug("Prepared event row: %s", row)
            rows.append(row)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Å–æ–±—ã—Ç–∏—è: %s, item=%s", e, item)

    if not rows:
        logger.info("–ù–µ—Ç —Å–æ–±—ã—Ç–∏–π –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏")
        return

    try:
        res = safe_execute(supabase.table("events").upsert(rows, on_conflict="event_id"))
        inserted = len(res.data or [])
        logger.info("‚úÖ Upsert events: %s prepared, %s inserted/updated", len(rows), inserted)
        return res
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ —Å–æ–±—ã—Ç–∏–π –≤ Supabase: %s", e)


# üëâ –ê–ª–∏–∞—Å
upsert_events = upsert_event


# --- –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π ---
def get_latest_events(limit: int = 10) -> List[Dict]:
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, get_latest_events –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.")
        return []

    query = (
        supabase.table("events")
        .select(
            "event_time, country, country_code, currency, title, importance, fact, forecast, previous, source"
        )
        .order("event_time", desc=False)
        .limit(limit)
    )

    try:
        data = safe_execute(query).data or []
        logger.debug("get_latest_events: fetched %d rows", len(data))
        for ev in data:
            ev["event_time_fmt"] = format_datetime(ev.get("event_time"))
            try:
                ev["importance"] = int(ev.get("importance") or 0)
            except Exception:
                ev["importance"] = 0
        return data
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–±—ã—Ç–∏–π: %s", e)
        return []


# --- –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π ---
def get_latest_news(
    source: Optional[str] = None,
    categories: Optional[List[str]] = None,
    limit: int = 10,
) -> List[Dict]:
    if not supabase:
        logger.warning("‚ö†Ô∏è Supabase –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω, get_latest_news –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç.")
        return []

    logger.debug("get_latest_news: source=%s, categories=%s, limit=%s", source, categories, limit)

    query = (
        supabase.table("news")
        .select(
            "id, uid, title, content, link, published_at, source, category, credibility, importance"
        )
        .order("published_at", desc=True)
        .limit(limit)
    )

    if source:
        query = query.eq("source", source)
    if categories:
        cats = [c.lower() for c in categories]
        query = query.in_("category", cats)

    try:
        data = safe_execute(query).data or []
        logger.debug("get_latest_news: fetched %d rows", len(data))
        for row in data:
            # –ü–∞—Ä—Å–∏–º published_at –≤ datetime –æ–±—ä–µ–∫—Ç
            row["published_at"] = parse_datetime_from_row(row.get("published_at"))
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            row["published_at_fmt"] = format_datetime(row.get("published_at"))
        return data
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: %s", e)
        return []
