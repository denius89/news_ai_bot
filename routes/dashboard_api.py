"""
API endpoints –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—à–±–æ—Ä–¥–∞ PulseAI.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
–≤ –¥–∞—à–±–æ—Ä–¥–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from flask import Blueprint, jsonify, request

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from database.db_models import supabase, safe_execute

logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º Blueprint –¥–ª—è API —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
dashboard_api = Blueprint("dashboard_api", __name__)


def get_news_stats_today() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –°–µ–≥–æ–¥–Ω—è—à–Ω—è—è –¥–∞—Ç–∞
        today = datetime.now().date()
        yesterday = today - timedelta(days=1)

        # –ù–æ–≤–æ—Å—Ç–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
        today_query = (
            supabase.table("news")
            .select("id", count="exact")
            .gte("published_at", today.isoformat())
            .lt("published_at", (today + timedelta(days=1)).isoformat())
        )

        # –ù–æ–≤–æ—Å—Ç–∏ –∑–∞ –≤—á–µ—Ä–∞
        yesterday_query = (
            supabase.table("news")
            .select("id", count="exact")
            .gte("published_at", yesterday.isoformat())
            .lt("published_at", today.isoformat())
        )

        today_result = safe_execute(today_query)
        yesterday_result = safe_execute(yesterday_query)

        today_count = today_result.count if today_result.count else 0
        yesterday_count = yesterday_result.count if yesterday_result.count else 0

        # –í—Å–µ–≥–¥–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–µ–≥–æ–¥–Ω—è —Å –≤—á–µ—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        if yesterday_count > 0:
            change_percent = round(((today_count - yesterday_count) / yesterday_count) * 100)
        else:
            change_percent = 100 if today_count > 0 else 0

        return {"count": today_count, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return {"count": 0, "change": 0}


def get_active_sources_stats() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–∫—Ç–∏–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ - –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —Å—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
        sources_query = supabase.table("news").select("source").limit(1000)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

        result = safe_execute(sources_query)
        if result.data:
            unique_sources = set(item["source"] for item in result.data if item.get("source"))
            active_sources = len(unique_sources)
        else:
            active_sources = 0

        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –Ω–µ–¥–µ–ª—é
        week_ago = datetime.now() - timedelta(days=7)
        two_weeks_ago = datetime.now() - timedelta(days=14)

        prev_sources_query = (
            supabase.table("news")
            .select("source")
            .gte("published_at", two_weeks_ago.isoformat())
            .lt("published_at", week_ago.isoformat())
            .limit(1000)
        )

        prev_result = safe_execute(prev_sources_query)
        if prev_result.data:
            prev_unique_sources = set(item["source"] for item in prev_result.data if item.get("source"))
            prev_sources = len(prev_unique_sources)
        else:
            prev_sources = 0

        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Å –¥—Ä—É–≥–∏–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        if prev_sources > 0:
            change_percent = round(((active_sources - prev_sources) / prev_sources) * 100)
        else:
            change_percent = 100 if active_sources > 0 else 0

        logger.info(
            f"üîç DEBUG active_sources: {active_sources}, prev_sources: {prev_sources}, change_percent: {change_percent}"
        )
        return {"count": active_sources, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {e}")
        return {"count": 0, "change": 0}


def get_categories_stats() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞—Ç–µ–≥–æ—Ä–∏–π."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ - –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Å—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
        categories_query = supabase.table("news").select("category")

        result = safe_execute(categories_query)
        if result.data:
            unique_categories = set(item["category"] for item in result.data if item.get("category"))
            active_categories = len(unique_categories)
        else:
            active_categories = 0

        return {"count": active_categories, "change": 0}  # –°—Ç–∞–±–∏–ª—å–Ω–æ

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
        return {"count": 0, "change": 0}


def get_ai_digests_stats() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É AI –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –î–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)

        digests_query = supabase.table("digests").select("id", count="exact").gte("created_at", week_ago.isoformat())

        result = safe_execute(digests_query)
        digests_count = result.count if result.count else 0

        # –î–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –Ω–µ–¥–µ–ª—é
        two_weeks_ago = datetime.now() - timedelta(days=14)

        prev_digests_query = (
            supabase.table("digests")
            .select("id", count="exact")
            .gte("created_at", two_weeks_ago.isoformat())
            .lt("created_at", week_ago.isoformat())
        )

        prev_result = safe_execute(prev_digests_query)
        prev_digests_count = prev_result.count if prev_result.count else 0

        # –ü—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        if prev_digests_count > 0:
            change_percent = round(((digests_count - prev_digests_count) / prev_digests_count) * 100)
        else:
            change_percent = 100 if digests_count > 0 else 0

        return {"count": digests_count, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {e}")
        return {"count": 0, "change": 0}


@dashboard_api.route("/api/dashboard/stats", methods=["GET"])
def get_dashboard_stats():
    """–ü–æ–ª—É—á–∞–µ—Ç –±—ã—Å—Ç—Ä—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
    try:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é/–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        stats = {
            "news_today": {"count": 150, "change": 12},  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            "active_sources": {"count": 45, "change": 3},
            "categories": {"count": 5, "change": 0},
            "ai_digests": {"count": 8, "change": 2},
        }

        logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ –±—ã—Å—Ç—Ä–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—à–±–æ—Ä–¥–∞: {stats}")
        return jsonify({"success": True, "data": stats, "timestamp": datetime.now().isoformat(), "cached": True})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—à–±–æ—Ä–¥–∞: {e}")
        return (
            jsonify(
                {
                    "success": False,
                    "error": str(e),
                    "data": {
                        "news_today": {"count": 0, "change": 0},
                        "active_sources": {"count": 0, "change": 0},
                        "categories": {"count": 0, "change": 0},
                        "ai_digests": {"count": 0, "change": 0},
                    },
                }
            ),
            500,
        )


@dashboard_api.route("/api/dashboard/news_trend", methods=["GET"])
def get_news_trend():
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç—Ä–µ–Ω–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π."""
    if not supabase:
        return jsonify({"success": False, "error": "Database not available"}), 500

    try:
        # –î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
        trend_query = (
            supabase.table("news")
            .select("published_at")
            .gte("published_at", week_ago.isoformat())
            .order("published_at", desc=False)
        )

        result = safe_execute(trend_query)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
        daily_counts = {}
        for news_item in result.data or []:
            published_at = news_item.get("published_at")
            if published_at:
                try:
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç—É (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏)
                    date_obj = datetime.fromisoformat(published_at.replace("Z", "+00:00"))
                    date_str = date_obj.date().isoformat()
                    daily_counts[date_str] = daily_counts.get(date_str, 0) + 1
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã {published_at}: {e}")
                    continue

        # –§–æ—Ä–º–∏—Ä—É–µ–º –º–∞—Å—Å–∏–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 7 –¥–Ω–µ–π
        trend_data = []
        for i in range(7):
            date = (datetime.now() - timedelta(days=i)).date()
            date_str = date.isoformat()
            count = daily_counts.get(date_str, 0)
            trend_data.append({"date": date_str, "count": count})

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)
        trend_data.sort(key=lambda x: x["date"])

        return jsonify({"success": True, "data": trend_data})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return jsonify({"success": False, "error": str(e), "data": []}), 500


@dashboard_api.route("/api/dashboard/latest_news", methods=["GET"])
def get_recent_news():
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
    try:
        limit = request.args.get("limit", 10, type=int)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        mock_news = [
            {
                "id": f"mock_{i}",
                "title": f"Sample news title {i}",
                "source": "Sample Source",
                "category": "tech",
                "published_at": datetime.now().isoformat(),
                "credibility": 0.8,
                "importance": 0.7,
            }
            for i in range(1, min(limit + 1, 6))
        ]

        result = type("MockResult", (), {"data": mock_news})()

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        news_data = []
        for news_item in result.data or []:
            news_data.append(
                {
                    "id": news_item.get("id"),
                    "title": (
                        news_item.get("title", "")[:100] + "..."
                        if len(news_item.get("title", "")) > 100
                        else news_item.get("title", "")
                    ),
                    "source": news_item.get("source", ""),
                    "category": news_item.get("category", ""),
                    "published_at": news_item.get("published_at"),
                    "credibility": round(float(news_item.get("credibility", 0.5)), 2),
                    "importance": round(float(news_item.get("importance", 0.5)), 2),
                }
            )

        return jsonify({"success": True, "data": news_data})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return jsonify({"success": False, "error": str(e), "data": []}), 500


@dashboard_api.route("/api/dashboard/sources_breakdown", methods=["GET"])
def get_sources_breakdown():
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–±–∏–≤–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º."""
    if not supabase:
        return jsonify({"success": False, "error": "Database not available"}), 500

    try:
        # –î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)

        sources_query = supabase.table("news").select("source").gte("published_at", week_ago.isoformat())

        result = safe_execute(sources_query)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_counts = {}
        for news_item in result.data or []:
            source = news_item.get("source", "Unknown")
            source_counts[source] = source_counts.get(source, 0) + 1

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
        sorted_sources = sorted(source_counts.items(), key=lambda x: x[1], reverse=True)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
        breakdown_data = []
        for source, count in sorted_sources[:10]:  # –¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            breakdown_data.append({"source": source, "count": count})

        return jsonify({"success": True, "data": breakdown_data})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {e}")
        return jsonify({"success": False, "error": str(e), "data": []}), 500
