"""
API endpoints –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—à–±–æ—Ä–¥–∞ PulseAI.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
–≤ –¥–∞—à–±–æ—Ä–¥–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞.
"""

import logging
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional
from flask import Blueprint, jsonify, request

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
import sys
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from database.db_models import supabase, safe_execute

logger = logging.getLogger(__name__)

# –°–æ–∑–¥–∞–µ–º Blueprint –¥–ª—è API —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
dashboard_api = Blueprint("dashboard_api", __name__)


def get_news_stats_today() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –°–µ–≥–æ–¥–Ω—è—à–Ω—è—è –¥–∞—Ç–∞ –≤ UTC (–¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
        today = datetime.now(timezone.utc).date()
        yesterday = today - timedelta(days=1)

        # –ù–æ–≤–æ—Å—Ç–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è (UTC)
        today_query = (
            supabase.table("news")
            .select("id", count="exact")
            .gte("published_at", today.isoformat())
            .lt("published_at", (today + timedelta(days=1)).isoformat())
        )

        # –ù–æ–≤–æ—Å—Ç–∏ –∑–∞ –≤—á–µ—Ä–∞ (UTC)
        yesterday_query = (
            supabase.table("news")
            .select("id", count="exact")
            .gte("published_at", yesterday.isoformat())
            .lt("published_at", today.isoformat())
        )

        today_result = safe_execute(today_query)
        yesterday_result = safe_execute(yesterday_query)

        today_count = today_result.count if today_result.count else 0
        yesterday_count = yesterday_result.count if yesterday_result.count else 0

        # –í—Å–µ–≥–¥–∞ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å–µ–≥–æ–¥–Ω—è —Å –≤—á–µ—Ä–∞ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        if yesterday_count > 0:
            change_percent = round(((today_count - yesterday_count) / yesterday_count) * 100)
        else:
            change_percent = 100 if today_count > 0 else 0

        return {"count": today_count, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return {"count": 0, "change": 0}


def get_active_users_stats() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        today = datetime.now()
        week_ago = today - timedelta(days=7)
        two_weeks_ago = today - timedelta(days=14)

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é (—Å–æ–∑–¥–∞–≤–∞–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç—ã)
        current_users_query = (
            supabase.table("digests").select("user_id").gte("created_at", week_ago.isoformat()).limit(1000)
        )

        current_result = safe_execute(current_users_query)
        if current_result.data:
            unique_current_users = set(item["user_id"] for item in current_result.data if item.get("user_id"))
            active_users = len(unique_current_users)
        else:
            active_users = 0

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –Ω–µ–¥–µ–ª—é
        prev_users_query = (
            supabase.table("digests")
            .select("user_id")
            .gte("created_at", two_weeks_ago.isoformat())
            .lt("created_at", week_ago.isoformat())
            .limit(1000)
        )

        prev_result = safe_execute(prev_users_query)
        if prev_result.data:
            unique_prev_users = set(item["user_id"] for item in prev_result.data if item.get("user_id"))
            prev_users = len(unique_prev_users)
        else:
            prev_users = 0

        # –ü—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
        if prev_users > 0:
            change_percent = round(((active_users - prev_users) / prev_users) * 100)
        else:
            change_percent = 100 if active_users > 0 else 0

        logger.info(
            f"üë• –ê–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏: —Ç–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è={active_users}, –ø—Ä–µ–¥—ã–¥—É—â–∞—è={prev_users}, –∏–∑–º–µ–Ω–µ–Ω–∏–µ={change_percent}%"
        )
        return {"count": active_users, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        return {"count": 0, "change": 0}


def get_events_stats() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–æ–±—ã—Ç–∏–π –Ω–∞ –Ω–µ–¥–µ–ª—é."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –°–æ–±—ã—Ç–∏—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–µ 7 –¥–Ω–µ–π
        now = datetime.now(timezone.utc)
        week_later = now + timedelta(days=7)

        current_events_query = (
            supabase.table("events_new")
            .select("id", count="exact")
            .gte("starts_at", now.isoformat())
            .lte("starts_at", week_later.isoformat())
        )

        current_result = safe_execute(current_events_query)
        current_count = current_result.count if current_result.count else 0

        # –°–æ–±—ã—Ç–∏—è –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –Ω–µ–¥–µ–ª—é (–¥–ª—è —Ç—Ä–µ–Ω–¥–∞)
        week_ago = now - timedelta(days=7)

        prev_events_query = (
            supabase.table("events_new")
            .select("id", count="exact")
            .gte("starts_at", week_ago.isoformat())
            .lte("starts_at", now.isoformat())
        )

        prev_result = safe_execute(prev_events_query)
        prev_count = prev_result.count if prev_result.count else 0

        # –ü—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
        if prev_count > 0:
            change_percent = round(((current_count - prev_count) / prev_count) * 100)
        else:
            change_percent = 100 if current_count > 0 else 0

        logger.info(f"üìÖ –°–æ–±—ã—Ç–∏—è: —Ç–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è={current_count}, –ø—Ä–µ–¥—ã–¥—É—â–∞—è={prev_count}, –∏–∑–º–µ–Ω–µ–Ω–∏–µ={change_percent}%")
        return {"count": current_count, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π: {e}")
        return {"count": 0, "change": 0}


def get_ai_digests_stats() -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É AI –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤."""
    if not supabase:
        return {"count": 0, "change": 0}

    try:
        # –î–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)

        digests_query = supabase.table("digests").select("id", count="exact").gte("created_at", week_ago.isoformat())

        result = safe_execute(digests_query)
        digests_count = result.count if result.count else 0

        # –î–∞–π–¥–∂–µ—Å—Ç—ã –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –Ω–µ–¥–µ–ª—é
        two_weeks_ago = datetime.now() - timedelta(days=14)

        prev_digests_query = (
            supabase.table("digests")
            .select("id", count="exact")
            .gte("created_at", two_weeks_ago.isoformat())
            .lt("created_at", week_ago.isoformat())
        )

        prev_result = safe_execute(prev_digests_query)
        prev_digests_count = prev_result.count if prev_result.count else 0

        # –ü—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–º–µ—Å—Ç–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
        if prev_digests_count > 0:
            change_percent = round(((digests_count - prev_digests_count) / prev_digests_count) * 100)
        else:
            change_percent = 100 if digests_count > 0 else 0

        return {"count": digests_count, "change": change_percent}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤: {e}")
        return {"count": 0, "change": 0}


@dashboard_api.route("/api/dashboard/stats", methods=["GET"])
def get_dashboard_stats():
    """–ü–æ–ª—É—á–∞–µ—Ç –±—ã—Å—Ç—Ä—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
        logger.info("üìä –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞—à–±–æ—Ä–¥–∞...")

        stats = {
            "news_today": get_news_stats_today(),
            "active_users": get_active_users_stats(),
            "events_week": get_events_stats(),
            "ai_digests": get_ai_digests_stats(),
        }

        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞—à–±–æ—Ä–¥–∞: {stats}")
        return jsonify({"success": True, "data": stats, "timestamp": datetime.now().isoformat(), "cached": False})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–∞—à–±–æ—Ä–¥–∞: {e}")
        return (
            jsonify(
                {
                    "success": False,
                    "error": str(e),
                    "data": {
                        "news_today": {"count": 0, "change": 0},
                        "active_users": {"count": 0, "change": 0},
                        "events_week": {"count": 0, "change": 0},
                        "ai_digests": {"count": 0, "change": 0},
                    },
                }
            ),
            500,
        )


@dashboard_api.route("/api/dashboard/news_trend", methods=["GET"])
def get_news_trend():
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç—Ä–µ–Ω–¥ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π."""
    if not supabase:
        return jsonify({"success": False, "error": "Database not available"}), 500

    try:
        # –î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
        trend_query = (
            supabase.table("news")
            .select("published_at")
            .gte("published_at", week_ago.isoformat())
            .order("published_at", desc=False)
        )

        result = safe_execute(trend_query)

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
        daily_counts = {}
        for news_item in result.data or []:
            published_at = news_item.get("published_at")
            if published_at:
                try:
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –∏ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç—É (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–∏)
                    date_obj = datetime.fromisoformat(published_at.replace("Z", "+00:00"))
                    date_str = date_obj.date().isoformat()
                    daily_counts[date_str] = daily_counts.get(date_str, 0) + 1
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã {published_at}: {e}")
                    continue

        # –§–æ—Ä–º–∏—Ä—É–µ–º –º–∞—Å—Å–∏–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 7 –¥–Ω–µ–π
        trend_data = []
        for i in range(7):
            date = (datetime.now() - timedelta(days=i)).date()
            date_str = date.isoformat()
            count = daily_counts.get(date_str, 0)
            trend_data.append({"date": date_str, "count": count})

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–æ—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º)
        trend_data.sort(key=lambda x: x["date"])

        return jsonify({"success": True, "data": trend_data})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return jsonify({"success": False, "error": str(e), "data": []}), 500


@dashboard_api.route("/api/dashboard/latest_news", methods=["GET"])
def get_recent_news():
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)."""
    try:
        limit = request.args.get("limit", 10, type=int)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        mock_news = [
            {
                "id": f"mock_{i}",
                "title": f"Sample news title {i}",
                "source": "Sample Source",
                "category": "tech",
                "published_at": datetime.now().isoformat(),
                "credibility": 0.8,
                "importance": 0.7,
            }
            for i in range(1, min(limit + 1, 6))
        ]

        result = type("MockResult", (), {"data": mock_news})()

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        news_data = []
        for news_item in result.data or []:
            news_data.append(
                {
                    "id": news_item.get("id"),
                    "title": (
                        news_item.get("title", "")[:100] + "..."
                        if len(news_item.get("title", "")) > 100
                        else news_item.get("title", "")
                    ),
                    "source": news_item.get("source", ""),
                    "category": news_item.get("category", ""),
                    "published_at": news_item.get("published_at"),
                    "credibility": round(float(news_item.get("credibility", 0.5)), 2),
                    "importance": round(float(news_item.get("importance", 0.5)), 2),
                }
            )

        return jsonify({"success": True, "data": news_data})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return jsonify({"success": False, "error": str(e), "data": []}), 500


@dashboard_api.route("/api/dashboard/sources_breakdown", methods=["GET"])
def get_sources_breakdown():
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞–∑–±–∏–≤–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º."""
    if not supabase:
        return jsonify({"success": False, "error": "Database not available"}), 500

    try:
        # –î–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
        week_ago = datetime.now() - timedelta(days=7)

        sources_query = supabase.table("news").select("source").gte("published_at", week_ago.isoformat())

        result = safe_execute(sources_query)

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_counts = {}
        for news_item in result.data or []:
            source = news_item.get("source", "Unknown")
            source_counts[source] = source_counts.get(source, 0) + 1

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
        sorted_sources = sorted(source_counts.items(), key=lambda x: x[1], reverse=True)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
        breakdown_data = []
        for source, count in sorted_sources[:10]:  # –¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            breakdown_data.append({"source": source, "count": count})

        return jsonify({"success": True, "data": breakdown_data})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º: {e}")
        return jsonify({"success": False, "error": str(e), "data": []}), 500
