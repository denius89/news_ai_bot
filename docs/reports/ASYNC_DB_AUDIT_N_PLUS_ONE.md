# –ê—É–¥–∏—Ç N+1 Queries

**–î–∞—Ç–∞:** 2025-01-18  
**–°—Ç–∞—Ç—É—Å:** –ù–∞–π–¥–µ–Ω–æ 5 –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º

## Executive Summary

N+1 query problem - —ç—Ç–æ –∫–æ–≥–¥–∞ –¥–µ–ª–∞–µ—Ç—Å—è 1 –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞, –∞ –∑–∞—Ç–µ–º N –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ —Å–ø–∏—Å–∫–∞.

**–ü—Ä–æ–±–ª–µ–º—ã:**
- ‚ùå –¶–∏–∫–ª –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å DB –∑–∞–ø—Ä–æ—Å–æ–º –≤ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ (1 + N queries)
- ‚ùå –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ü–∏–∫–ª–µ
- ‚ùå –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ JOIN

**–û–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**
- ‚Üì 80-90% –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ DB queries
- ‚Üì 60-70% –æ–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- ‚Üë 5-10x —É—Å–∫–æ—Ä–µ–Ω–∏–µ endpoints

---

## üî¥ –ö–†–ò–¢–ò–ß–ù–û - N+1 Queries

### 1. `routes/news_routes.py:339-349` - Query per Category

```python
# ‚ùå –ü–õ–û–•–û: N+1 problem!
# –ï—Å–ª–∏ 10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π ‚Üí 10 DB queries!
for category in all_categories:  # all_categories = ["tech", "crypto", "world", ...]
    try:
        category_news = db_service.get_latest_news(
            categories=[category], limit=100
        )  # ‚Üê DB QUERY –≤ —Ü–∏–∫–ª–µ!
        news_by_category[category] = category_news
        logger.debug(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è {category}: {len(category_news)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
        news_by_category[category] = []
```

**–ü—Ä–æ–±–ª–µ–º–∞:**  
10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π ‚Üí 10 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö SQL –∑–∞–ø—Ä–æ—Å–æ–≤ ‚Üí 10x –º–µ–¥–ª–µ–Ω–Ω–µ–µ

**–†–µ—à–µ–Ω–∏–µ:**
```python
# ‚úÖ –•–û–†–û–®–û: 1 –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ N
# –í–∞—Ä–∏–∞–Ω—Ç 1: –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ —Å—Ä–∞–∑—É —Å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –≤ Python
all_news = db_service.get_latest_news(limit=1000)  # –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å

# –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ Python
news_by_category = {}
for category in all_categories:
    news_by_category[category] = []

for news in all_news:
    cat = news.get("category")
    if cat in news_by_category:
        news_by_category[cat].append(news)

# –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
for category in news_by_category:
    news_by_category[category] = news_by_category[category][:100]

# –í–∞—Ä–∏–∞–Ω—Ç 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SQL —Å GROUP BY (—Å–æ–∑–¥–∞—Ç—å RPC —Ñ—É–Ω–∫—Ü–∏—é)
# CREATE FUNCTION get_news_by_categories(cats TEXT[], limit_per_category INT)
# RETURNS TABLE(...) AS $$
#   SELECT DISTINCT ON (category) *
#   FROM news
#   WHERE category = ANY(cats)
#   ORDER BY category, importance DESC, published_at DESC
#   LIMIT limit_per_category
# $$ LANGUAGE SQL;
```

**–ú–µ—Ç—Ä–∏–∫–∏:**
- –î–æ: 10 –∑–∞–ø—Ä–æ—Å–æ–≤ √ó 100ms = 1000ms
- –ü–æ—Å–ª–µ: 1 –∑–∞–ø—Ä–æ—Å √ó 150ms = 150ms  
- –£—Å–∫–æ—Ä–µ–Ω–∏–µ: **6.7x**

---

### 2. `routes/news_routes.py:462-482` - Category Stats Loop

```python
# ‚ùå –ü–õ–û–•–û: N+1 problem –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
for category in categories:  # categories = ["tech", "crypto", ...]
    try:
        category_news = db_service.get_latest_news(
            categories=[category], limit=1000
        )  # ‚Üê DB QUERY –≤ —Ü–∏–∫–ª–µ!
        
        # –í—ã—á–∏—Å–ª—è–µ–º avg –≤ Python (–Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ)
        category_stats[category] = {
            "count": len(category_news),
            "avg_importance": sum(float(n.get("importance", 0.5)) for n in category_news) / len(category_news),
            "avg_credibility": sum(float(n.get("credibility", 0.5)) for n in category_news) / len(category_news),
        }
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
        category_stats[category] = {"count": 0, "avg_importance": 0, "avg_credibility": 0}
```

**–ü—Ä–æ–±–ª–µ–º–∞:**  
10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π √ó 1000 –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∂–¥–∞—è = 10,000 –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏!

**–†–µ—à–µ–Ω–∏–µ:**
```python
# ‚úÖ –•–û–†–û–®–û: –û–¥–∏–Ω SQL –∑–∞–ø—Ä–æ—Å —Å GROUP BY
# –°–æ–∑–¥–∞—Ç—å RPC —Ñ—É–Ω–∫—Ü–∏—é –≤ Supabase:

# CREATE OR REPLACE FUNCTION get_all_category_stats()
# RETURNS TABLE(
#   category TEXT,
#   count BIGINT,
#   avg_importance FLOAT,
#   avg_credibility FLOAT
# ) AS $$
#   SELECT 
#     category,
#     COUNT(*) as count,
#     AVG(importance) as avg_importance,
#     AVG(credibility) as avg_credibility
#   FROM news
#   WHERE category IS NOT NULL
#   GROUP BY category
#   ORDER BY count DESC;
# $$ LANGUAGE SQL STABLE;

# –í Python:
category_stats_result = supabase.rpc("get_all_category_stats").execute()
category_stats = {
    row["category"]: {
        "count": row["count"],
        "avg_importance": row["avg_importance"],
        "avg_credibility": row["avg_credibility"],
    }
    for row in category_stats_result.data
}
```

**–ú–µ—Ç—Ä–∏–∫–∏:**
- –î–æ: 10 –∑–∞–ø—Ä–æ—Å–æ–≤ √ó 200ms + 10,000 –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∞ = 2500ms
- –ü–æ—Å–ª–µ: 1 –∑–∞–ø—Ä–æ—Å √ó 50ms = 50ms  
- –£—Å–∫–æ—Ä–µ–Ω–∏–µ: **50x**

---

### 3. `routes/dashboard_api.py:80-106` - Sources Count Loop

```python
# ‚ùå –ü–õ–û–•–û: 2 –∑–∞–ø—Ä–æ—Å–∞ –ø–æ 1000 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö
sources_query = supabase.table("news").select("source").limit(1000)
result = safe_execute(sources_query)

# –ó–∞–≥—Ä—É–∂–∞–µ–º 1000 –∑–∞–ø–∏—Å–µ–π —á—Ç–æ–±—ã –ø–æ—Å—á–∏—Ç–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ Python
unique_sources = set(item["source"] for item in result.data if item.get("source"))
active_sources = len(unique_sources)

# –ó–∞—Ç–µ–º –µ—â–µ 1000 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø—Ä–æ—à–ª–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
prev_sources_query = supabase.table("news").select("source").limit(1000)
prev_result = safe_execute(prev_sources_query)
prev_unique_sources = set(item["source"] for item in prev_result.data if item.get("source"))
```

**–ü—Ä–æ–±–ª–µ–º–∞:**  
2000 –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ COUNT(DISTINCT source)

**–†–µ—à–µ–Ω–∏–µ:**
```python
# ‚úÖ –•–û–†–û–®–û: SQL COUNT(DISTINCT)

# CREATE FUNCTION count_sources_in_period(
#   start_date timestamptz,
#   end_date timestamptz
# ) RETURNS bigint AS $$
#   SELECT COUNT(DISTINCT source)
#   FROM news
#   WHERE published_at >= start_date 
#     AND published_at < end_date;
# $$ LANGUAGE SQL STABLE;

# –í Python:
today = datetime.now()
week_ago = today - timedelta(days=7)
two_weeks_ago = today - timedelta(days=14)

current_sources = supabase.rpc("count_sources_in_period", {
    "start_date": week_ago.isoformat(),
    "end_date": today.isoformat()
}).execute()

prev_sources = supabase.rpc("count_sources_in_period", {
    "start_date": two_weeks_ago.isoformat(),
    "end_date": week_ago.isoformat()
}).execute()

active_sources = current_sources.data
prev_sources_count = prev_sources.data
```

**–ú–µ—Ç—Ä–∏–∫–∏:**
- –î–æ: 2 –∑–∞–ø—Ä–æ—Å–∞ √ó 150ms + 2000 –∑–∞–ø–∏—Å–µ–π = 400ms
- –ü–æ—Å–ª–µ: 2 –∑–∞–ø—Ä–æ—Å–∞ √ó 20ms = 40ms  
- –£—Å–∫–æ—Ä–µ–Ω–∏–µ: **10x**

---

### 4. `services/events_stream.py:106-120` - User Notifications Loop

```python
# üü° –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–û –ü–õ–û–•–û: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —á—Ç–æ –≤–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞
for user_id in target_users:  # target_users –º–æ–∂–µ—Ç –±—ã—Ç—å 100+ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    try:
        # Check rate limit
        if not self.can_send_update(user_id):  # ‚Üê –í–æ–∑–º–æ–∂–Ω–æ DB query?
            continue
        
        # Send update —á–µ—Ä–µ–∑ WebSocket (—ç—Ç–æ –æ–∫)
        await self._send_user_update(user_id, update_data)
    except Exception as e:
        logger.error(f"Error sending update to {user_id}: {e}")
```

**–¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏:**  
–ï—Å–ª–∏ `can_send_update()` –¥–µ–ª–∞–µ—Ç DB query ‚Üí N+1 problem

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
```python
# ‚úÖ –•–û–†–û–®–û: –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ rate limits –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º

# –î–æ —Ü–∏–∫–ª–∞:
user_ids = list(target_users)
rate_limits = await self.batch_check_rate_limits(user_ids)  # –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å

# –í —Ü–∏–∫–ª–µ:
for user_id in target_users:
    if not rate_limits.get(user_id, True):  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑ –ø–∞–º—è—Ç–∏
        continue
    
    await self._send_user_update(user_id, update_data)
```

---

### 5. `routes/admin_routes.py:1194-1213` - Events Providers Loop

```python
# üü° –°–†–ï–î–ù–ï: –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≤ Python –≤–º–µ—Å—Ç–æ SQL
providers_map = defaultdict(lambda: {"count": 0, "categories": set()})
category_counts = defaultdict(int)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å–æ–±—ã—Ç–∏—è
events_data = result.data or []

# –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –≤ Python (–º–æ–∂–Ω–æ –±—ã–ª–æ –≤ SQL)
for event in events_data:
    source = event.get("source", "Unknown")
    category = event.get("category", "other")
    providers_map[source]["count"] += 1
    providers_map[source]["categories"].add(category)
    category_counts[category] += 1
```

**–ü—Ä–æ–±–ª–µ–º–∞:**  
–•–æ—Ç—è —ç—Ç–æ –Ω–µ N+1 (–Ω–µ—Ç DB queries –≤ —Ü–∏–∫–ª–µ), –Ω–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≤ Python –º–µ–¥–ª–µ–Ω–Ω–µ–µ —á–µ–º –≤ SQL

**–†–µ—à–µ–Ω–∏–µ:**
```python
# ‚úÖ –•–û–†–û–®–û: GROUP BY –≤ SQL

# CREATE FUNCTION get_provider_stats()
# RETURNS TABLE(
#   source TEXT,
#   count BIGINT,
#   categories TEXT[]
# ) AS $$
#   SELECT 
#     source,
#     COUNT(*) as count,
#     array_agg(DISTINCT category) as categories
#   FROM events_new
#   GROUP BY source
#   ORDER BY count DESC;
# $$ LANGUAGE SQL STABLE;

providers_result = supabase.rpc("get_provider_stats").execute()
providers_map = {
    row["source"]: {
        "count": row["count"],
        "categories": set(row["categories"])
    }
    for row in providers_result.data
}
```

---

## üü¢ –ù–ï N+1 (–Ω–æ –≤—ã–≥–ª—è–¥–∏—Ç –ø–æ—Ö–æ–∂–µ)

### –õ–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è:

#### A. `routes/api_routes.py:223-236` - Unicode conversion
```python
# ‚úÖ –û–ö: –Ω–µ—Ç DB queries –≤ —Ü–∏–∫–ª–µ
for char in name:
    if char in unicode_map:
        result += unicode_map[char]
```
**–°—Ç–∞—Ç—É—Å:** –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–æ–∫–∏, –Ω–µ N+1

---

#### B. `routes/news_routes.py:78-89` - Model conversion
```python
# ‚úÖ –û–ö: –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π, –Ω–µ DB queries
for item in news_items:
    if hasattr(item, "model_dump"):
        item_dict = item.model_dump()
```
**–°—Ç–∞—Ç—É—Å:** –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –ø–∞–º—è—Ç–∏, –Ω–µ N+1

---

#### C. `services/notification_service.py:350-360` - Event formatting
```python
# ‚úÖ –û–ö: —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
for event in events[:5]:  # Events —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
    category_emoji = self._get_category_emoji(event.get("category"))
    title = event.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è")
```
**–°—Ç–∞—Ç—É—Å:** –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –ø–∞–º—è—Ç–∏, –Ω–µ N+1

---

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ SQL RPC —Ñ—É–Ω–∫—Ü–∏–∏

### RPC 1: Get News by Categories (batch)
```sql
CREATE OR REPLACE FUNCTION get_news_by_categories_batch(
  cats TEXT[],
  limit_per_category INT DEFAULT 100
)
RETURNS TABLE(
  category TEXT,
  id INT,
  title TEXT,
  content TEXT,
  importance FLOAT,
  credibility FLOAT,
  published_at TIMESTAMPTZ
) AS $$
  SELECT 
    category,
    id,
    title,
    content,
    importance,
    credibility,
    published_at
  FROM (
    SELECT *,
      ROW_NUMBER() OVER (PARTITION BY category ORDER BY importance DESC, published_at DESC) as rn
    FROM news
    WHERE category = ANY(cats)
  ) ranked
  WHERE rn <= limit_per_category;
$$ LANGUAGE SQL STABLE;
```

### RPC 2: Get All Category Stats
```sql
CREATE OR REPLACE FUNCTION get_all_category_stats()
RETURNS TABLE(
  category TEXT,
  count BIGINT,
  avg_importance FLOAT,
  avg_credibility FLOAT,
  latest_news_at TIMESTAMPTZ
) AS $$
  SELECT 
    category,
    COUNT(*) as count,
    AVG(importance) as avg_importance,
    AVG(credibility) as avg_credibility,
    MAX(published_at) as latest_news_at
  FROM news
  WHERE category IS NOT NULL
  GROUP BY category
  ORDER BY count DESC;
$$ LANGUAGE SQL STABLE;
```

### RPC 3: Count Sources in Period
```sql
CREATE OR REPLACE FUNCTION count_sources_in_period(
  start_date timestamptz,
  end_date timestamptz
)
RETURNS bigint AS $$
  SELECT COUNT(DISTINCT source)
  FROM news
  WHERE published_at >= start_date 
    AND published_at < end_date
    AND source IS NOT NULL;
$$ LANGUAGE SQL STABLE;
```

### RPC 4: Provider Stats
```sql
CREATE OR REPLACE FUNCTION get_provider_stats()
RETURNS TABLE(
  source TEXT,
  event_count BIGINT,
  categories TEXT[],
  avg_importance FLOAT
) AS $$
  SELECT 
    source,
    COUNT(*) as event_count,
    array_agg(DISTINCT category) as categories,
    AVG(importance) as avg_importance
  FROM events_new
  WHERE source IS NOT NULL
  GROUP BY source
  ORDER BY event_count DESC;
$$ LANGUAGE SQL STABLE;
```

---

## –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π

### –ù–µ–¥–µ–ª—è 1 (–ö—Ä–∏—Ç–∏—á–Ω–æ):
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å RPC —Ñ—É–Ω–∫—Ü–∏–∏ –≤ Supabase (1 —á–∞—Å)
2. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å `routes/news_routes.py:339` - N+1 –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (30 –º–∏–Ω)
3. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å `routes/news_routes.py:462` - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (30 –º–∏–Ω)

**–í—Ä–µ–º—è:** 2 —á–∞—Å–∞  
**–≠—Ñ—Ñ–µ–∫—Ç:** ‚Üì 80% DB queries, ‚Üë 5-10x —Å–∫–æ—Ä–æ—Å—Ç—å endpoints

---

### –ù–µ–¥–µ–ª—è 2 (–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è):
4. ‚è≥ –ò—Å–ø—Ä–∞–≤–∏—Ç—å `routes/dashboard_api.py:80` - sources count (30 –º–∏–Ω)
5. ‚è≥ –ò—Å–ø—Ä–∞–≤–∏—Ç—å `routes/admin_routes.py:1194` - provider stats (30 –º–∏–Ω)
6. ‚è≥ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å `services/events_stream.py:106` –Ω–∞ DB queries (1 —á–∞—Å)

**–í—Ä–µ–º—è:** 2 —á–∞—Å–∞  
**–≠—Ñ—Ñ–µ–∫—Ç:** ‚Üì 60% time –≤ admin endpoints

---

## –ò–∑–º–µ—Ä–∏–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏

### –î–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
```python
# /api/latest-weighted endpoint
# –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î: 10 (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é)
# –í—Ä–µ–º—è: 1000-1500 ms
# –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: 1000 (100 √ó 10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)

# /api/distribution-stats endpoint
# –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î: 10 (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é)
# –í—Ä–µ–º—è: 2000-3000 ms
# –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: 10,000 (1000 √ó 10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)

# /api/admin/providers endpoint
# –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î: 1 (–Ω–æ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≤ Python)
# –í—Ä–µ–º—è: 300-500 ms
# –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: 1000+
```

### –ü–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
```python
# /api/latest-weighted endpoint
# –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î: 1 (RPC —Ñ—É–Ω–∫—Ü–∏—è)
# –í—Ä–µ–º—è: 150-250 ms (‚Üì 80%)
# –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: 1000

# /api/distribution-stats endpoint
# –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î: 1 (RPC —Ñ—É–Ω–∫—Ü–∏—è —Å GROUP BY)
# –í—Ä–µ–º—è: 50-100 ms (‚Üì 95%)
# –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: 10 (—Ç–æ–ª—å–∫–æ –∞–≥—Ä–µ–≥–∞—Ç—ã)

# /api/admin/providers endpoint
# –ó–∞–ø—Ä–æ—Å–æ–≤ –∫ –ë–î: 1 (RPC —Å GROUP BY)
# –í—Ä–µ–º—è: 50-100 ms (‚Üì 80%)
# –ó–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: 20-50 (—Ç–æ–ª—å–∫–æ –∞–≥—Ä–µ–≥–∞—Ç—ã)
```

---

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### 1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DB Views –¥–ª—è —á–∞—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
```sql
-- View –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
CREATE VIEW category_stats AS
SELECT 
  category,
  COUNT(*) as total_news,
  AVG(importance) as avg_importance,
  AVG(credibility) as avg_credibility,
  MAX(published_at) as latest_news_at
FROM news
WHERE category IS NOT NULL
GROUP BY category;

-- –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ:
SELECT * FROM category_stats;
```

### 2. Batch loading pattern
```python
# –ï—Å–ª–∏ –Ω—É–∂–Ω—ã —Å–≤—è–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
def get_users_with_preferences(user_ids: List[int]):
    # ‚ùå –ü–õ–û–•–û: N+1
    users = []
    for user_id in user_ids:
        user = db.get_user(user_id)
        prefs = db.get_preferences(user_id)
        users.append({**user, "preferences": prefs})
    
    # ‚úÖ –•–û–†–û–®–û: 2 –∑–∞–ø—Ä–æ—Å–∞ –≤–º–µ—Å—Ç–æ 2N
    users = db.get_users_batch(user_ids)  # 1 –∑–∞–ø—Ä–æ—Å
    prefs = db.get_preferences_batch(user_ids)  # 1 –∑–∞–ø—Ä–æ—Å
    prefs_map = {p["user_id"]: p for p in prefs}
    
    return [
        {**user, "preferences": prefs_map.get(user["id"])}
        for user in users
    ]
```

### 3. DataLoader pattern (–¥–ª—è GraphQL-–ø–æ–¥–æ–±–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤)
```python
from collections import defaultdict

class BatchLoader:
    def __init__(self):
        self.queue = []
        self.cache = {}
    
    async def load(self, key):
        if key in self.cache:
            return self.cache[key]
        
        self.queue.append(key)
        
        # Batch load when queue reaches threshold
        if len(self.queue) >= 10:
            await self._flush()
        
        return self.cache.get(key)
    
    async def _flush(self):
        if not self.queue:
            return
        
        # –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ N
        results = await db.get_batch(self.queue)
        
        for item in results:
            self.cache[item["id"]] = item
        
        self.queue.clear()
```

---

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

**–ù–∞–π–¥–µ–Ω–æ:** 5 N+1 –ø—Ä–æ–±–ª–µ–º (3 –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö, 2 —Å—Ä–µ–¥–Ω–∏—Ö)

**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:**
- üî¥ 2 –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö (—Ü–∏–∫–ª—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å DB queries)
- üü° 3 —Å—Ä–µ–¥–Ω–∏—Ö (–Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞/–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞)
- üü¢ 0 –Ω–∏–∑–∫–∏—Ö

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:**
1. –°–æ–∑–¥–∞—Ç—å RPC —Ñ—É–Ω–∫—Ü–∏–∏ –≤ Supabase
2. –ó–∞–º–µ–Ω–∏—Ç—å —Ü–∏–∫–ª—ã —Å DB queries –Ω–∞ batch loading
3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SQL GROUP BY –≤–º–µ—Å—Ç–æ Python –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚Üì 80-90% –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ DB queries
- ‚Üì 60-70% –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è endpoints
- ‚Üë 5-10x —É—Å–∫–æ—Ä–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö endpoints
- ‚Üì 50% –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ –ë–î

**–í—Ä–µ–º—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:** 4-6 —á–∞—Å–æ–≤ —Ä–∞–±–æ—Ç—ã (2 –Ω–µ–¥–µ–ª–∏ –ø–æ 2-3 —á–∞—Å–∞)


