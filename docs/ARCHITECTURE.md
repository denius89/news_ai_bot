# PulseAI System Architecture

PulseAI is built as an ETL pipeline with AI analysis and output to different interfaces.

## Table of Contents

- [System Overview](#system-overview)
- [Architecture Diagram](#architecture-diagram)
- [Core Components](#core-components)
- [Data Flow](#data-flow)
- [Technology Stack](#technology-stack)
- [Database Schema](#database-schema)
- [API Design](#api-design)
- [Deployment Architecture](#deployment-architecture)

## System Overview

PulseAI transforms chaotic news and events streams into structured, AI-analyzed content delivered through multiple interfaces including web applications, Telegram bots, and APIs.

## Architecture Diagram

```mermaid
flowchart TD
    A["ğŸŒ Data Sources<br/>RSS, Websites, Calendars"] --> B["âš™ï¸ Data Parsers<br/>rss_parser, events_parser, utils"]
    B --> C["ğŸ¤– AI Analysis Modules<br/>credibility, importance, summary"]
    C --> D["ğŸ—„ï¸ Supabase Database<br/>PostgreSQL"]
    D --> E["ğŸ“° Digest Generation<br/>Morning/Evening, AI-texts"]
    D --> F["ğŸ“… Events Calendar<br/>Macro + Crypto Events"]
    D --> G["ğŸŒ Web Application<br/>Flask + Templates"]
    D --> H["ğŸ¤– Telegram Bot<br/>aiogram 3.x"]
    D --> I["ğŸ“± API Endpoints<br/>REST API"]
    
    J["ğŸ”§ Services Layer<br/>DigestAIService, DigestService"] --> E
    K["ğŸ“Š Repositories Layer<br/>NewsRepository, EventsRepository"] --> D
    L["ğŸ¨ Utils Layer<br/>Formatters, Cleaners"] --> B
```

## Core Components

### Data Sources
- **RSS Feeds** â€” News from crypto, economy, world, tech categories
- **Economic Calendars** â€” Investing.com events parsing
- **News Websites** â€” Direct scraping capabilities

### Data Processing Layer
- **Parsers** â€” Data extraction and cleaning modules
  - `parsers/rss_parser.py` â€” RSS feed processing
  - `parsers/events_parser.py` â€” Economic events parsing
  - `utils/clean_text.py` â€” HTML cleaning and text normalization
- **AI Modules** â€” Content analysis and scoring
  - `ai_modules/credibility.py` â€” News credibility assessment
  - `ai_modules/importance.py` â€” News importance scoring
  - `digests/ai_summary.py` â€” AI-powered digest generation

### Data Storage
- **Supabase (PostgreSQL)** â€” Primary database
  - `news` table â€” News articles with AI scores
  - `events` table â€” Economic events with priorities
  - `users` table â€” User management (future)
  - `subscriptions` table â€” User preferences (future)

### Business Logic Layer
- **Services** â€” Core business logic
  - `services/digest_service.py` â€” Digest generation
  - `services/digest_ai_service.py` â€” AI-powered digest service
- **Repositories** â€” Data access layer
  - `repositories/news_repository.py` â€” News data operations
  - `repositories/events_repository.py` â€” Events data operations

### Presentation Layer
- **Web Application** â€” Flask-based web interface
  - Templates for news, events, and digests
  - Responsive design with mobile support
- **Telegram Bot** â€” aiogram 3.x based bot
  - Inline navigation and commands
  - AI digest generation by categories
- **CLI Interface** â€” Command-line tools
  - `main.py` â€” Main CLI application
  - `tools/` â€” Utility scripts

## Data Flow Diagram

```mermaid
flowchart LR
    A["ğŸ“¥ Data Sources<br/>RSS, Websites, Calendars"] --> B["âš™ï¸ Parsers<br/>rss_parser.py<br/>events_parser.py"]
    B --> C["ğŸ§¹ Data Cleaning<br/>clean_text.py<br/>deduplication"]
    C --> D["ğŸ—„ï¸ Database<br/>Supabase PostgreSQL<br/>news, events tables"]
    D --> E["ğŸ¤– AI Modules<br/>credibility.py<br/>importance.py<br/>ai_summary.py"]
    E --> F["ğŸ“Š Repositories<br/>news_repository.py<br/>events_repository.py"]
    F --> G["ğŸ”§ Services<br/>digest_service.py<br/>digest_ai_service.py"]
    G --> H["ğŸ“¤ Output<br/>Telegram Bot<br/>Web App<br/>API"]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#e0f2f1
    style G fill:#f1f8e9
    style H fill:#e3f2fd
```

## Technology Stack

### Backend
- **Python 3.11+** â€” Main programming language
- **Flask** â€” Web framework
- **Supabase** â€” Database and authentication
- **OpenAI API** â€” AI analysis and content generation
- **aiogram 3.x** â€” Telegram bot framework

### Data Processing
- **Requests** â€” HTTP client for data fetching
- **Feedparser** â€” RSS feed parsing
- **BeautifulSoup** â€” HTML parsing and cleaning
- **Pydantic** â€” Data validation and models

### Development Tools
- **Pytest** â€” Testing framework
- **Black** â€” Code formatting
- **Flake8** â€” Code linting
- **Mypy** â€” Type checking

## Database Schema

### News Table
```sql
CREATE TABLE news (
    uid TEXT PRIMARY KEY,           -- SHA256 hash of URL+title
    title TEXT NOT NULL,            -- News headline
    link TEXT,                      -- Source URL
    published_at TIMESTAMPTZ,      -- Publication time (UTC)
    content TEXT,                   -- News content
    credibility NUMERIC,            -- AI credibility score
    importance NUMERIC,             -- AI importance score
    source TEXT,                    -- Source name
    category TEXT                   -- News category
);
```

### Events Table
```sql
CREATE TABLE events (
    id UUID PRIMARY KEY,            -- Unique identifier
    title TEXT NOT NULL,            -- Event name
    country TEXT,                   -- Country code
    currency TEXT,                  -- Currency code
    importance INTEGER,             -- Priority (1-3)
    event_time TIMESTAMPTZ,         -- Event time (UTC)
    fact TEXT,                      -- Actual value
    forecast TEXT,                  -- Forecast value
    previous TEXT,                  -- Previous value
    source TEXT                     -- Source name
);
```

## API Design

### REST Endpoints
- `GET /api/news` â€” Retrieve news articles
- `GET /api/events` â€” Retrieve events
- `POST /api/digest` â€” Generate digest
- `GET /api/digest/{id}` â€” Get specific digest

### Query Parameters
- `limit` â€” Number of items to return
- `category` â€” Filter by category
- `date_from` â€” Start date filter
- `date_to` â€” End date filter

## Deployment Architecture

### Development Environment
- Local Python virtual environment
- Supabase development database
- Local file-based logging

### Production Environment
- **Render** â€” Application hosting
- **Supabase** â€” Production database
- **GitHub Actions** â€” CI/CD pipeline
- **Telegram Bot** â€” Deployed bot instance

### Monitoring
- Application logs via Python logging
- Database monitoring via Supabase
- Error tracking and alerting
- Performance metrics collection

## Security Considerations

- API rate limiting
- Input validation and sanitization
- Secure environment variable management
- Database access controls
- HTTPS enforcement

## Scalability Considerations

- Horizontal scaling via load balancers
- Database connection pooling
- Caching strategies for frequently accessed data
- Asynchronous processing for AI operations
- CDN for static assets