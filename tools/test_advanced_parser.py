#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è AdvancedParser —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –Ω–æ–≤–æ—Å—Ç–µ–π.

–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ 10 –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.
"""

import asyncio
import logging
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from parsers.advanced_parser import AdvancedParser
from database.service import get_async_service
from ai_modules.importance import evaluate_importance
from ai_modules.credibility import evaluate_credibility
from utils.clean_text import clean_text
import feedparser

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("logs/test_advanced_parser.log", encoding="utf-8"),
    ],
)

logger = logging.getLogger(__name__)


class TestAdvancedParser(AdvancedParser):
    """–¢–µ—Å—Ç–æ–≤–∞—è –≤–µ—Ä—Å–∏—è AdvancedParser —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏."""

    def __init__(self, max_news_per_subcategory=10, **kwargs):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞.

        Args:
            max_news_per_subcategory: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—é
        """
        super().__init__(**kwargs)
        self.max_news_per_subcategory = max_news_per_subcategory
        self.subcategory_counts = {}

    async def _process_rss_source(self, category, subcategory, name, url, content):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ RSS –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É."""
        try:
            feed = feedparser.parse(content)
            if not feed.entries:
                return {"success": False, "reason": "no_entries"}

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –¥–ª—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if subcategory not in self.subcategory_counts:
                self.subcategory_counts[subcategory] = 0

            if self.subcategory_counts[subcategory] >= self.max_news_per_subcategory:
                logger.info(f"[{category}/{subcategory}] –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {self.max_news_per_subcategory} –Ω–æ–≤–æ—Å—Ç–µ–π")
                return {
                    "success": True,
                    "processed": 0,
                    "saved": 0,
                    "type": "rss",
                    "reason": "limit_reached",
                }

            processed_count = 0
            saved_count = 0

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
            max_entries = min(
                len(feed.entries),
                self.max_news_per_subcategory - self.subcategory_counts[subcategory],
            )

            for entry in feed.entries[:max_entries]:
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ RSS
                    title = clean_text(entry.get("title", ""))
                    link = entry.get("link", "")
                    summary = clean_text(entry.get("summary", ""))

                    if not title:
                        continue

                    processed_count += 1

                    # –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
                    text_for_ai = f"{title} {summary}".strip()
                    if not text_for_ai:
                        continue

                    importance = evaluate_importance({"title": title, "content": text_for_ai})
                    credibility = evaluate_credibility({"title": title, "content": text_for_ai})

                    if importance < self.min_importance:
                        logger.debug(f"[{category}/{subcategory}] {title} -> SKIP (importance: {importance:.2f})")
                        continue

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                    news_item = {
                        "title": title,
                        "content": summary,
                        "link": link,
                        "source": name,
                        "category": category,
                        "subcategory": subcategory,
                        "importance": importance,
                        "credibility": credibility,
                    }

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –ë–î
                    db_service = get_async_service()
                    await db_service.async_upsert_news([news_item])
                    saved_count += 1
                    self.subcategory_counts[subcategory] += 1

                    logger.info(f"[{category}/{subcategory}] {title[:50]}... -> SAVED (importance: {importance:.2f})")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ RSS –∑–∞–ø–∏—Å–∏: {e}")
                    continue

            return {
                "success": True,
                "processed": processed_count,
                "saved": saved_count,
                "type": "rss",
            }

        except Exception as e:
            return {"success": False, "reason": f"rss_parse_error: {e}"}

    async def _process_html_source(self, category, subcategory, name, url, content):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ HTML –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É."""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –¥–ª—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            if subcategory not in self.subcategory_counts:
                self.subcategory_counts[subcategory] = 0

            if self.subcategory_counts[subcategory] >= self.max_news_per_subcategory:
                logger.info(f"[{category}/{subcategory}] –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {self.max_news_per_subcategory} –Ω–æ–≤–æ—Å—Ç–µ–π")
                return {
                    "success": True,
                    "processed": 0,
                    "saved": 0,
                    "type": "html",
                    "reason": "limit_reached",
                }

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∫–∞—Å–∫–∞–¥–Ω—ã–º –º–µ—Ç–æ–¥–æ–º
            extracted = self._extract_content_cascade(url, content)
            if not extracted:
                return {"success": False, "reason": "content_extraction_failed"}

            title = extracted["title"]
            maintext = extracted["maintext"]
            method = extracted["method"]

            if not title or not maintext:
                return {"success": False, "reason": "insufficient_content"}

            # –û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
            text_for_ai = f"{title} {maintext}".strip()
            importance = evaluate_importance({"title": title, "content": text_for_ai})
            credibility = evaluate_credibility({"title": title, "content": text_for_ai})

            if importance < self.min_importance:
                logger.debug(f"[{category}/{subcategory}] {title} -> SKIP (importance: {importance:.2f})")
                return {"success": False, "reason": "low_importance", "importance": importance}

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            news_item = {
                "title": title,
                "content": maintext,
                "link": url,
                "source": name,
                "category": category,
                "subcategory": subcategory,
                "importance": importance,
                "credibility": credibility,
            }

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –ë–î
            db_service = get_async_service()
            await db_service.async_upsert_news([news_item])

            self.subcategory_counts[subcategory] += 1

            logger.info(f"[{category}/{subcategory}] {url} -> SUCCESS ({method}, importance: {importance:.2f})")

            return {
                "success": True,
                "processed": 1,
                "saved": 1,
                "type": "html",
                "method": method,
                "importance": importance,
                "credibility": credibility,
            }

        except Exception as e:
            return {"success": False, "reason": f"html_parse_error: {e}"}


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞."""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è AdvancedParser")
    print("üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: –ø–æ 10 –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—é")

    try:
        async with TestAdvancedParser(
            max_concurrent=5,  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Ç–µ—Å—Ç–∞
            min_importance=0.2,  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            max_news_per_subcategory=10,
        ) as parser:

            stats = await parser.run()

            print("\n" + "=" * 60)
            print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
            print("=" * 60)
            print(f"üì∞ –í—Å–µ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {stats.get('total_sources', 0)}")
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats.get('successful', 0)}")
            print(f"‚ùå –ù–µ—É–¥–∞—á–Ω–æ: {stats.get('failed', 0)}")
            print(f"üîÑ –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats.get('total_processed', 0)}")
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î: {stats.get('total_saved', 0)}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            if hasattr(parser, "subcategory_counts"):
                print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                for subcategory, count in parser.subcategory_counts.items():
                    print(f"   ‚Ä¢ {subcategory}: {count} –Ω–æ–≤–æ—Å—Ç–µ–π")

            if stats.get("errors"):
                print(f"\n‚ö†Ô∏è  –û—à–∏–±–∫–∏ ({len(stats['errors'])}):")
                for error in stats["errors"][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                    print(f"   ‚Ä¢ {error}")
                if len(stats["errors"]) > 5:
                    print(f"   ... –∏ –µ—â–µ {len(stats['errors']) - 5} –æ—à–∏–±–æ–∫")

            print("=" * 60)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if stats.get("total_saved", 0) > 0:
                return 0  # –£—Å–ø–µ—Ö
            else:
                return 1  # –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        return 2


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
