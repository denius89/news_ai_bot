import logging
import os
from datetime import datetime, timezone

from dotenv import load_dotenv
from supabase import create_client

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()],
)

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env
load_dotenv()
url = os.getenv("SUPABASE_URL")
key = os.getenv("SUPABASE_KEY")
client = create_client(url, key)


def fix_news():
    logging.info("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –±–∞–∑—ã...")
    response = client.table("news").select("*").execute()
    rows = response.data
    logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(rows)} –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")

    fixed = 0
    for row in rows:
        update_needed = False
        data = {}

        # published_at fallback
        if not row.get("published_at"):
            data["published_at"] = datetime.now(timezone.utc).isoformat()
            update_needed = True

        # credibility fallback
        if row.get("credibility") is None:
            data["credibility"] = 0.5
            update_needed = True

        # importance fallback
        if row.get("importance") is None:
            data["importance"] = 0.5
            update_needed = True

        # content fallback
        if not row.get("content"):
            data["content"] = row.get("title", "")
            update_needed = True

        if update_needed:
            client.table("news").update(data).eq("id", row["id"]).execute()
            fixed += 1

    logging.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {fixed} –Ω–æ–≤–æ—Å—Ç–µ–π")


if __name__ == "__main__":
    fix_news()
