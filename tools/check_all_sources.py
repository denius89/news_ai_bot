#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ config/sources.yaml
"""

import asyncio
import aiohttp
import yaml
import xml.etree.ElementTree as ET
from pathlib import Path
from urllib.parse import urljoin, urlparse
import logging
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SourceChecker:
    def __init__(self):
        self.results = []
        self.session = None
        self.total_sources = 0
        self.valid_sources = 0
        self.invalid_sources = 0

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=10), headers={"User-Agent": "Mozilla/5.0 (compatible; PulseAI Bot)"}
        )
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def check_url(self, url: str) -> tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å URL"""
        try:
            async with self.session.get(url) as response:
                if response.status == 200:
                    content_type = response.headers.get("content-type", "").lower()
                    if "xml" in content_type or "rss" in content_type or "atom" in content_type:
                        return True, "‚úÖ OK (RSS/XML)"
                    else:
                        return False, f"‚ùå HTML –≤–º–µ—Å—Ç–æ RSS (Content-Type: {content_type})"
                elif response.status == 404:
                    return False, "‚ùå 404 Not Found"
                elif response.status == 403:
                    return False, "‚ùå 403 Forbidden"
                elif response.status == 301 or response.status == 302:
                    return False, f"‚ùå Redirect ({response.status})"
                else:
                    return False, f"‚ùå HTTP {response.status}"
        except asyncio.TimeoutError:
            return False, "‚ùå Timeout"
        except aiohttp.ClientError as e:
            return False, f"‚ùå Connection Error: {str(e)}"
        except Exception as e:
            return False, f"‚ùå Error: {str(e)}"

    async def check_rss_structure(self, url: str) -> tuple[bool, str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É RSS"""
        try:
            async with self.session.get(url) as response:
                if response.status != 200:
                    return False, f"‚ùå HTTP {response.status}"

                content = await response.text()

                try:
                    root = ET.fromstring(content)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ RSS
                    items = root.findall(".//item") or root.findall(".//entry")
                    if not items:
                        return False, "‚ùå No <item> or <entry> elements found"

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
                    for item in items[:3]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —ç–ª–µ–º–µ–Ω—Ç–∞
                        title = item.find("title") or item.find("{http://purl.org/rss/1.0/}title")
                        link = item.find("link") or item.find("{http://purl.org/rss/1.0/}link")

                        if title is None or link is None:
                            return False, "‚ùå Missing title or link in RSS items"

                    return True, f"‚úÖ OK (RSS with {len(items)} items)"

                except ET.ParseError:
                    return False, "‚ùå Invalid XML structure"

        except Exception as e:
            return False, f"‚ùå RSS Check Error: {str(e)}"

    async def try_rss_alternatives(self, base_url: str) -> str:
        """–ü—Ä–æ–±—É–µ—Ç –Ω–∞–π—Ç–∏ RSS –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã"""
        alternatives = [
            f"{base_url}/feed",
            f"{base_url}/rss",
            f"{base_url}/rss.xml",
            f"{base_url}/feed.xml",
            f"{base_url}/feeds/all.rss",
        ]

        for alt_url in alternatives:
            try:
                async with self.session.get(alt_url) as response:
                    if response.status == 200:
                        content_type = response.headers.get("content-type", "").lower()
                        if "xml" in content_type or "rss" in content_type:
                            return f"üîÑ Try: {alt_url}"
            except:
                continue

        return "‚ùå No RSS alternatives found"

    async def check_source(self, category: str, subcategory: str, source: dict) -> None:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫"""
        name = source.get("name", "Unknown")
        url = source.get("url", "")

        if not url:
            result = "‚ùå Empty URL"
            self.results.append((category, subcategory, name, url, result))
            self.invalid_sources += 1
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å URL
        is_accessible, access_result = await self.check_url(url)

        if is_accessible:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É RSS
            is_valid_rss, rss_result = await self.check_rss_structure(url)
            if is_valid_rss:
                result = rss_result
                self.valid_sources += 1
            else:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
                alternatives = await self.try_rss_alternatives(url.rstrip("/"))
                result = f"{access_result} | {rss_result} | {alternatives}"
                self.invalid_sources += 1
        else:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
            alternatives = await self.try_rss_alternatives(url.rstrip("/"))
            result = f"{access_result} | {alternatives}"
            self.invalid_sources += 1

        self.results.append((category, subcategory, name, url, result))
        logger.info(f"Checked: {category}/{subcategory} - {name}")

    async def check_all_sources(self, sources_config: dict) -> None:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏"""
        for category, cat_data in sources_config.items():
            if category == "version" or not isinstance(cat_data, dict):
                continue

            for subcategory, sub_data in cat_data.items():
                if not isinstance(sub_data, dict) or "sources" not in sub_data:
                    continue

                sources = sub_data["sources"]
                if not isinstance(sources, list):
                    continue

                for source in sources:
                    self.total_sources += 1
                    await self.check_source(category, subcategory, source)

    def save_results(self, log_file: str = "logs/bad_sources.log") -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª"""
        Path("logs").mkdir(exist_ok=True)

        with open(log_file, "w", encoding="utf-8") as f:
            f.write(f"# Source Check Report - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            for category, subcategory, name, url, result in self.results:
                f.write(f"[{category}/{subcategory}] {name}: {url} ‚Äî {result}\n")

        logger.info(f"Results saved to {log_file}")

    def print_statistics(self) -> None:
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print("\n" + "=" * 60)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–í–ï–†–ö–ò –ò–°–¢–û–ß–ù–ò–ö–û–í")
        print("=" * 60)
        print(f"üìà –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {self.total_sources}")
        print(f"‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {self.valid_sources}")
        print(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {self.invalid_sources}")
        print(
            f"üìä –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏: {(self.valid_sources/self.total_sources*100):.1f}%"
            if self.total_sources > 0
            else "0%"
        )

        # –¢–æ–ø 5 –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        invalid_results = [
            (cat, sub, name, url, result) for cat, sub, name, url, result in self.results if "‚ùå" in result
        ]

        if invalid_results:
            print(f"\nüî¥ –¢–û–ü-5 –ù–ï–í–ê–õ–ò–î–ù–´–• –ò–°–¢–û–ß–ù–ò–ö–û–í:")
            for i, (category, subcategory, name, url, result) in enumerate(invalid_results[:5], 1):
                print(f"{i}. [{category}/{subcategory}] {name}")
                print(f"   URL: {url}")
                print(f"   –ü—Ä–æ–±–ª–µ–º–∞: {result}")
                print()

        print("=" * 60)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    try:
        with open("config/sources.yaml", "r", encoding="utf-8") as f:
            sources_config = yaml.safe_load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ config/sources.yaml: {e}")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    async with SourceChecker() as checker:
        await checker.check_all_sources(sources_config)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    checker.save_results()

    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    checker.print_statistics()

    print("\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    asyncio.run(main())
