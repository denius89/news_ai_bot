#!/usr/bin/env python3
"""
–£–º–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
1. –ü–∞—Ä—Å–∏—Ç —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
2. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python tools/news/fetch_and_train.py
    python tools/news/fetch_and_train.py --force-train  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    python tools/news/fetch_and_train.py --skip-train   # –¢–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥
"""

import asyncio
import argparse
import json
import logging
import sys
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Optional, List, Dict

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from parsers.advanced_parser import AdvancedParser
from ai_modules.self_tuning_collector import get_self_tuning_collector
from ai_modules.self_tuning_trainer import get_self_tuning_trainer
from ai_modules.metrics import get_metrics
from tools.news.progress_state import (
    reset_progress_state,
    update_progress_state,
    get_progress_state as get_state_for_api,
    load_progress_state,
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("logs/fetch_and_train.log", encoding="utf-8"),
    ],
)

logger = logging.getLogger(__name__)


# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è progress_state.py


def log_progress(event_type: str = "parsing_progress", **extra_data):
    """
    –õ–æ–≥–∏—Ä—É–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è real-time –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.

    Args:
        event_type: –¢–∏–ø —Å–æ–±—ã—Ç–∏—è
        **extra_data: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ JSON —Ñ–∞–π–ª–∞
    state = load_progress_state()

    progress_percent = 0
    if state["sources_total"] > 0:
        progress_percent = round((state["sources_processed"] / state["sources_total"]) * 100, 1)

    # –í—ã—á–∏—Å–ª—è–µ–º ETA
    eta_seconds = 0
    if state["start_time"] and state["sources_processed"] > 0:
        try:
            start_time = datetime.fromisoformat(state["start_time"].replace("Z", "+00:00"))
            elapsed = (datetime.now(timezone.utc) - start_time).total_seconds()
            avg_time_per_source = elapsed / state["sources_processed"]
            remaining_sources = state["sources_total"] - state["sources_processed"]
            eta_seconds = int(avg_time_per_source * remaining_sources)
        except (ValueError, TypeError):
            eta_seconds = 0

    log_data = {
        "event": event_type,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "sources_total": state["sources_total"],
        "sources_processed": state["sources_processed"],
        "sources_remaining": state["sources_total"] - state["sources_processed"],
        "progress_percent": progress_percent,
        "news_found": state["news_found"],
        "news_saved": state["news_saved"],
        "news_filtered": state["news_filtered"],
        "errors_count": state["errors_count"],
        "current_source": state["current_source"],
        "eta_seconds": eta_seconds,
        **extra_data,
    }

    logger.info(json.dumps(log_data))


def update_progress(
    sources_total: int = None,
    sources_processed_delta: int = 0,
    news_found_delta: int = 0,
    news_saved_delta: int = 0,
    news_filtered_delta: int = 0,
    current_source: str = None,
    error: Dict = None,
    source_stats: Dict = None,
    category: str = None,
    ai_stats: Dict = None,
):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —á–µ—Ä–µ–∑ JSON —Ñ–∞–π–ª."""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    update_progress_state(
        sources_total=sources_total,
        sources_processed_delta=sources_processed_delta,
        news_found_delta=news_found_delta,
        news_saved_delta=news_saved_delta,
        news_filtered_delta=news_filtered_delta,
        current_source=current_source,
        error=error,
        source_stats=source_stats,
        category=category,
        ai_stats=ai_stats,
    )

    # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
    if sources_total is not None:
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–≥–¥–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è sources_total
        log_progress(event_type="sources_initialized", sources_total=sources_total)
    elif sources_processed_delta > 0:
        # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 2 –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
        state = load_progress_state()
        if state["sources_processed"] % 2 == 0:
            log_progress()
    elif error:
        log_progress(event_type="parsing_error", error=error)
    elif current_source:
        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–∏ —Å–º–µ–Ω–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        log_progress(event_type="source_change", current_source=current_source)


def get_progress_state() -> Dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –¥–ª—è API.

    Returns:
        Dict —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–æ–¥—É–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    return get_state_for_api()


def should_retrain(trainer, force: bool = False) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ.

    Args:
        trainer: –≠–∫–∑–µ–º–ø–ª—è—Ä SelfTuningTrainer
        force: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

    Returns:
        True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    """
    if force:
        logger.info("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—à–µ–Ω–æ")
        return True

    try:
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        metadata = trainer._load_existing_metadata()

        if not metadata:
            logger.info("üìä –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ")
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
        last_training_str = metadata.get("timestamp")
        if not last_training_str:
            logger.info("‚è∞ –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –æ–±—É—á–µ–Ω–∏–∏")
            return True

        last_training = datetime.fromisoformat(last_training_str.replace("Z", "+00:00"))
        interval_days = trainer.config.get("self_tuning", {}).get("interval_days", 2)
        next_training = last_training + timedelta(days=interval_days)
        now = datetime.now(timezone.utc)

        if now >= next_training:
            days_since = (now - last_training).days
            logger.info(f"‚úÖ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –¥–æ—Å—Ç–∏–≥–Ω—É—Ç ({days_since} –¥–Ω–µ–π —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è)")
            return True
        else:
            remaining = next_training - now
            logger.info(f"‚è≥ –î–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –æ—Å—Ç–∞–ª–æ—Å—å: {remaining}")
            return False

    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è: {e}")
        return False


async def fetch_news(
    max_concurrent: int = 10, categories: Optional[List[str]] = None, subcategories: Optional[List[str]] = None
) -> dict:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

    Args:
        max_concurrent: –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        categories: –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        subcategories: –°–ø–∏—Å–æ–∫ —Å—É–±–∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

    Returns:
        –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
    """
    logger.info("üì∞ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π...")

    # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —á–µ—Ä–µ–∑ –Ω–æ–≤—ã–π –º–æ–¥—É–ª—å
    reset_progress_state()

    if categories:
        logger.info(f"üîç –§–∏–ª—å—Ç—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {categories}")
    if subcategories:
        logger.info(f"üîç –§–∏–ª—å—Ç—Ä —Å—É–±–∫–∞—Ç–µ–≥–æ—Ä–∏–π: {subcategories}")

    async with AdvancedParser(
        max_concurrent=max_concurrent, min_importance=0.1, categories=categories, subcategories=subcategories
    ) as parser:
        # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ __aenter__)
        total_sources = parser.get_total_sources_count()
        logger.info(f"üìç –ù–∞–π–¥–µ–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {total_sources}")
        if total_sources > 0:
            update_progress(sources_total=total_sources)
        else:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ - –≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏–ª–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏")

        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ sources_total
        log_progress(event_type="fetch_started", categories=categories, subcategories=subcategories)

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        stats = await parser.run()
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if stats:
            update_progress(
                sources_processed_delta=stats.get("successful", 0),
                news_saved_delta=stats.get("total_saved", 0),
                news_found_delta=stats.get("total_processed", 0),
                news_filtered_delta=stats.get("total_processed", 0) - stats.get("total_saved", 0),
            )

    logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {stats.get('total_sources', 0)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

    # –§–∏–Ω–∞–ª—å–Ω—ã–π –ª–æ–≥
    final_state = load_progress_state()
    log_progress(
        event_type="fetch_completed",
        final_stats={
            "total_sources": stats.get("total_sources", 0),
            "news_found": final_state["news_found"],
            "news_saved": final_state["news_saved"],
            "news_filtered": final_state["news_filtered"],
            "errors_count": final_state["errors_count"],
        },
    )

    return stats


def train_models(force_train: bool = False) -> dict:
    """
    –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

    Args:
        force_train: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
    """
    logger.info("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è...")

    collector = get_self_tuning_collector()
    trainer = get_self_tuning_trainer()

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –≤–∫–ª—é—á–µ–Ω–æ –ª–∏ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ
    if not collector.is_enabled() or not trainer.is_enabled():
        logger.warning("‚ö†Ô∏è Self-tuning –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        return {"success": False, "reason": "disabled"}

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    if not should_retrain(trainer, force=force_train):
        logger.info("‚è≠Ô∏è –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return {"success": True, "reason": "interval_not_reached"}

    # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    logger.info("üìä –°–±–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    collection_result = collector.collect_training_data()

    if not collection_result["success"]:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {collection_result.get('error')}")
        return collection_result

    dataset_size = collection_result["dataset_size"]
    logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {dataset_size} –ø—Ä–∏–º–µ—Ä–æ–≤")

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    logger.info("üß† –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    dataset_path = Path(collection_result["dataset_path"])
    training_result = trainer.train_models(dataset_path)

    if not training_result["success"]:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {training_result.get('error')}")
        return training_result

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    improvements = training_result.get("improvements", {})
    for model_name, result in improvements.items():
        f1_score = result.get("f1_score", 0.0)
        improvement = result.get("improvement", 0.0)
        replaced = result.get("replaced", False)

        status = "‚úÖ –ó–ê–ú–ï–ù–ï–ù–ê" if replaced else "‚è∏Ô∏è –ù–ï –ó–ê–ú–ï–ù–ï–ù–ê"
        logger.info(f"   {model_name}: F1={f1_score:.3f}, —É–ª—É—á—à–µ–Ω–∏–µ={improvement:.3f} ({status})")

    logger.info("üéâ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    return training_result


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(description="–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
    parser.add_argument(
        "--max-concurrent",
        type=int,
        default=10,
        help="–ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 10)",
    )

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    parser.add_argument(
        "--force-train",
        action="store_true",
        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤–∞–ª)",
    )
    parser.add_argument(
        "--skip-train",
        action="store_true",
        help="–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥)",
    )

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    parser.add_argument(
        "--categories",
        type=str,
        help="–°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)",
    )
    parser.add_argument(
        "--subcategories",
        type=str,
        help="–°–ø–∏—Å–æ–∫ —Å—É–±–∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)",
    )

    # –î—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--verbose", "-v", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–º–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –∞–≤—Ç–æ–æ–±—É—á–µ–Ω–∏–µ–º")
    logger.info("=" * 60)

    start_time = datetime.now(timezone.utc)

    try:
        # –®–∞–≥ 1: –ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–≤–æ—Å—Ç–µ–π
        logger.info("üì∞ –®–ê–ì 1: –ü–∞—Ä—Å–∏–Ω–≥ —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π")
        logger.info("-" * 60)

        # –ü–∞—Ä—Å–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        categories = None
        if args.categories:
            categories = [cat.strip() for cat in args.categories.split(",")]

        subcategories = None
        if args.subcategories:
            subcategories = [subcat.strip() for subcat in args.subcategories.split(",")]

        fetch_stats = await fetch_news(
            max_concurrent=args.max_concurrent, categories=categories, subcategories=subcategories
        )

        if not fetch_stats.get("total_saved", 0):
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        logger.info("")

        # –®–∞–≥ 2: –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        if not args.skip_train:
            logger.info("ü§ñ –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            logger.info("-" * 60)

            train_result = train_models(force_train=args.force_train)

            if train_result.get("success"):
                if train_result.get("reason") == "interval_not_reached":
                    logger.info("‚è≠Ô∏è –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ (–∏–Ω—Ç–µ—Ä–≤–∞–ª –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç)")
                elif train_result.get("reason") == "disabled":
                    logger.info("‚è≠Ô∏è Self-tuning –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                else:
                    logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω—ã")
            else:
                logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è")
        else:
            logger.info("‚è≠Ô∏è –®–ê–ì 2: –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ (--skip-train)")

        logger.info("")

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        duration = (datetime.now(timezone.utc) - start_time).total_seconds()

        logger.info("=" * 60)
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        logger.info("=" * 60)
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f}—Å")
        logger.info(f"üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {fetch_stats.get('total_sources', 0)}")
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {fetch_stats.get('successful', 0)}")
        logger.info(f"‚ùå –û—à–∏–±–æ–∫: {fetch_stats.get('failed', 0)}")
        logger.info(f"üíæ –ù–æ–≤–æ—Å—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {fetch_stats.get('total_saved', 0)}")

        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        metrics = get_metrics()
        metrics_summary = metrics.get_metrics_summary()

        if metrics_summary.get("self_tuning_last_run_timestamp"):
            logger.info(f"ü§ñ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±—É—á–µ–Ω–∏–µ: {metrics_summary['self_tuning_last_run_timestamp']}")
            logger.info(f"üéØ –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: v{metrics_summary['self_tuning_current_model_version']}")
            logger.info(f"üìä –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {metrics_summary['self_tuning_dataset_size']}")

        logger.info("=" * 60)
        logger.info("üéâ –í—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")

        return 0

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
