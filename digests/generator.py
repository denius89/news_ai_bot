import argparse
import logging
from database.db_models import supabase
from digests.ai_summary import generate_summary  # –º–æ–¥—É–ª—å AI-—Å–∞–º–º–∞—Ä–∏
from datetime import datetime

logger = logging.getLogger(__name__)


def fetch_recent_news(limit: int = 5):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –±–∞–∑—ã (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ importance –∏ –¥–∞—Ç–µ).
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª–µ published_at_fmt –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    if not supabase:
        logger.warning(
            "‚ö†Ô∏è Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π."
        )
        return []

    response = (
        supabase.table("news")
        .select("id, title, content, link, importance, published_at, source, category")
        .order("importance", desc=True)
        .order("published_at", desc=True)
        .limit(limit)
        .execute()
    )

    rows = response.data or []
    news = []

    for row in rows:
        # —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
        published_at_fmt = "‚Äî"
        if row.get("published_at"):
            try:
                dt = datetime.fromisoformat(row["published_at"].replace("Z", "+00:00"))
                published_at_fmt = dt.strftime("%d %b %Y, %H:%M")
            except Exception:
                pass

        row["published_at_fmt"] = published_at_fmt
        news.append(row)

    return news


def generate_digest(limit: int = 5, ai: bool = False) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–∞–π–¥–∂–µ—Å—Ç–∞:
    - –µ—Å–ª–∏ ai=True ‚Üí –¥–µ–ª–∞–µ–º AI-summary
    - –∏–Ω–∞—á–µ ‚Üí —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    news_items = fetch_recent_news(limit=limit)
    if not news_items:
        return "–°–µ–≥–æ–¥–Ω—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç."

    if ai:
        return generate_summary(news_items)

    # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–∞–π–¥–∂–µ—Å—Ç
    lines = []
    for i, item in enumerate(news_items, 1):
        title = item.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
        link = item.get("link", "")
        date = item.get("published_at_fmt", "‚Äî")
        lines.append(f"{i}. {title} [{date}] ({link})")

    digest_text = "üì∞ –î–∞–π–¥–∂–µ—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π:\n\n" + "\n".join(lines)
    return digest_text


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--ai", action="store_true", help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞"
    )
    parser.add_argument(
        "--limit", type=int, default=5, help="–°–∫–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤–∫–ª—é—á–∞—Ç—å"
    )
    args = parser.parse_args()

    print(generate_digest(limit=args.limit, ai=args.ai))
