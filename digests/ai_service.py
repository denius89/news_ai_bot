"""
AI Digest Service - centralized AI-powered digest generation.

This module contains the main DigestAIService class that handles:
- News digest generation with AI analysis
- Fallback to simple format when OpenAI API is not available
- Date formatting and news limiting (max 8 items)
"""

import logging
import asyncio
from datetime import datetime
from typing import List, Optional, Dict, Any
from dataclasses import dataclass

from models.news import NewsItem
from utils.formatters import format_date
from utils.ai_client import ask_async

logger = logging.getLogger(__name__)


@dataclass
class DigestConfig:
    """Configuration for digest generation."""
    max_items: int = 8
    include_fallback: bool = True
    style: str = "analytical"


class DigestAIService:
    """
    AI-powered digest generation service.
    
    Handles both AI-enhanced and fallback digest generation.
    """
    
    def __init__(self, config: Optional[DigestConfig] = None):
        self.config = config or DigestConfig()
        self._openai_available = self._check_openai_availability()
        
    def _check_openai_availability(self) -> bool:
        """Check if OpenAI API is available."""
        try:
            import openai
            return bool(openai.api_key)
        except (ImportError, AttributeError):
            return False
    
    async def build_digest(
        self, 
        news_items: List[NewsItem], 
        style: str = "analytical"
    ) -> str:
        """
        Build AI-powered digest from news items.
        
        Args:
            news_items: List of NewsItem objects
            style: Digest style (analytical, business, meme)
            
        Returns:
            Formatted digest string
        """
        if not news_items:
            return self._build_empty_digest()
        
        # Limit to max_items
        limited_news = news_items[:self.config.max_items]
        
        if self._openai_available:
            try:
                return await self._llm_summarize(limited_news, style)
            except Exception as e:
                logger.warning(f"AI summarization failed, using fallback: {e}")
                return self._build_fallback_digest(limited_news)
        else:
            logger.info("OpenAI API not available, using fallback digest")
            return self._build_fallback_digest(limited_news)
    
    async def _llm_summarize(self, news_items: List[NewsItem], style: str) -> str:
        """
        Generate AI-powered summary using OpenAI.
        
        Args:
            news_items: List of news items to summarize
            style: Summary style
            
        Returns:
            AI-generated digest text
        """
        # Prepare news data for AI
        news_data = []
        for item in news_items:
            news_data.append({
                "title": item.title,
                "content": item.content or "",
                "published_at": item.published_at_fmt if item.published_at else "Unknown",
                "source": item.source or "Unknown",
                "credibility": item.credibility or 0.0,
                "importance": item.importance or 0.0
            })
        
        # Create prompt based on style
        prompt = self._create_prompt(news_data, style)
        
        # Call OpenAI API
        response = await ask_async(
            prompt=prompt,
            style=style,
            max_tokens=1000
        )
        
        # Add fallback section if not present
        if self.config.include_fallback and "<b>–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ" not in response:
            response += self._get_fallback_section()
        
        return response
    
    def _create_prompt(self, news_data: List[Dict[str, Any]], style: str) -> str:
        """Create AI prompt based on news data and style."""
        
        news_text = "\n\n".join([
            f"üì∞ {item['title']}\n"
            f"üìÖ {item['published_at']} | üîó {item['source']}\n"
            f"üìä –î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {item['credibility']:.1f} | –í–∞–∂–Ω–æ—Å—Ç—å: {item['importance']:.1f}\n"
            f"üìù {item['content'][:200]}..." if item['content'] else "üìù –û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"
            for item in news_data
        ])
        
        style_instructions = {
            "analytical": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç–∏ –∏ –æ–±—ä—è—Å–Ω–∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä—ã–Ω–∫–∞",
            "business": "–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –±–∏–∑–Ω–µ—Å-–∞—Å–ø–µ–∫—Ç–∞—Ö –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö",
            "meme": "–ü–∏—à–∏ –≤ –ª–µ–≥–∫–æ–º, —é–º–æ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–æ–º —Å—Ç–∏–ª–µ —Å —ç–º–æ–¥–∑–∏"
        }
        
        instruction = style_instructions.get(style, style_instructions["analytical"])
        
        return f"""
{instruction}

–ù–æ–≤–æ—Å—Ç–∏:
{news_text}

–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç (–¥–æ 500 —Å–ª–æ–≤) —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –≤–∞–∂–Ω–æ—Å—Ç–∏ —Å–æ–±—ã—Ç–∏–π.
–ò—Å–ø–æ–ª—å–∑—É–π HTML-—Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
"""
    
    def _build_fallback_digest(self, news_items: List[NewsItem]) -> str:
        """
        Build simple digest without AI when OpenAI is not available.
        
        Args:
            news_items: List of news items
            
        Returns:
            Simple formatted digest
        """
        digest_parts = ["üì∞ <b>–î–∞–π–¥–∂–µ—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π</b>\n"]
        
        for i, item in enumerate(news_items, 1):
            date_str = format_date(item.published_at) if item.published_at else "‚Äî"
            credibility = f"{item.credibility:.1f}" if item.credibility else "‚Äî"
            importance = f"{item.importance:.1f}" if item.importance else "‚Äî"
            
            digest_parts.append(
                f"<b>{i}. {item.title}</b>\n"
                f"üìÖ {date_str} | üîó {item.source or 'Unknown'}\n"
                f"üìä –î–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å: {credibility} | –í–∞–∂–Ω–æ—Å—Ç—å: {importance}\n"
            )
        
        # Add fallback section
        if self.config.include_fallback:
            digest_parts.append(self._get_fallback_section())
        
        return "\n".join(digest_parts)
    
    def _build_empty_digest(self) -> str:
        """Build digest for empty news list."""
        return "üì∞ <b>–î–∞–π–¥–∂–µ—Å—Ç –Ω–æ–≤–æ—Å—Ç–µ–π</b>\n\n–°–µ–≥–æ–¥–Ω—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ—Ç."
    
    def _get_fallback_section(self) -> str:
        """Get standard fallback section."""
        return """
<b>–ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:</b>
‚Äî –°–æ–±—ã—Ç–∏—è –≤–ª–∏—è—é—Ç –Ω–∞ —Ä—ã–Ω–æ–∫ –∏ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏
‚Äî –í–∞–∂–Ω–æ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π
‚Äî –ü–æ–º–æ–≥–∞–µ—Ç –ø–æ–Ω–∏–º–∞—Ç—å —Ç—Ä–µ–Ω–¥—ã –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
"""


# Convenience functions for backward compatibility
async def generate_ai_digest(
    news_items: List[NewsItem], 
    style: str = "analytical",
    max_items: int = 8
) -> str:
    """
    Generate AI digest from news items.
    
    Args:
        news_items: List of NewsItem objects
        style: Digest style
        max_items: Maximum number of items to include
        
    Returns:
        Generated digest text
    """
    config = DigestConfig(max_items=max_items)
    service = DigestAIService(config)
    return await service.build_digest(news_items, style)


def generate_fallback_digest(news_items: List[NewsItem], max_items: int = 8) -> str:
    """
    Generate fallback digest without AI.
    
    Args:
        news_items: List of NewsItem objects
        max_items: Maximum number of items to include
        
    Returns:
        Generated digest text
    """
    config = DigestConfig(max_items=max_items)
    service = DigestAIService(config)
    return service._build_fallback_digest(news_items[:max_items])
