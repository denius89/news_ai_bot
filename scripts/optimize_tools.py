#!/usr/bin/env python3
"""
üßπ –°–∫—Ä–∏–ø—Ç –∞–∫–∫—É—Ä–∞—Ç–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ tools
–ê–≤—Ç–æ—Ä: AI Assistant
–í–µ—Ä—Å–∏—è: 1.0

–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–∫–∏ tools
"""

import os
import shutil
from pathlib import Path
from datetime import datetime

class ToolsOptimizer:
    def __init__(self, project_root="."):
        self.project_root = Path(project_root)
        self.backup_dir = self.project_root / "tools_optimization_backup"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.tools_new = self.project_root / "tools_new"
        
        # –ú–∞–ø–ø–∏–Ω–≥ —Ñ–∞–π–ª–æ–≤ tools –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        self.tools_mapping = {
            # Management - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
            "run_all.py": "management/",
            "port_manager.py": "management/",
            
            # News - –†–∞–±–æ—Ç–∞ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ (–æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ)
            "fetch_and_store_news.py": "news/fetch_news.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "fetch_loop.py": "news/fetch_news.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "fetch_optimized.py": "news/fetch_news.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "load_fresh_news.py": "news/",
            "refresh_news.py": "news/",
            "clean_old_news.py": "news/",
            "update_news_with_universal_parser.py": "news/update_news.py",  # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º
            
            # Events - –†–∞–±–æ—Ç–∞ —Å —Å–æ–±—ã—Ç–∏—è–º–∏
            "fetch_and_store_events.py": "events/fetch_events.py",  # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º
            
            # Sources - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ (–æ–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ)
            "check_all_sources.py": "sources/check_sources.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "check_templates.py": "sources/check_sources.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "distribute_sources.py": "sources/distribute_sources.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "smart_distribute_sources.py": "sources/distribute_sources.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "merge_sources.py": "sources/",
            "update_rss_sources.py": "sources/validate_sources.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "validate_rss_sources.py": "sources/validate_sources.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            
            # AI - AI –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            "build_baseline_dataset.py": "ai/build_dataset.py",  # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º
            "fill_ai_analysis_all.py": "ai/train_models.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "train_self_tuning.py": "ai/train_models.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "analyze_rejections.py": "ai/analyze_data.py",  # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º
            
            # Frontend - CSS –∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–æ–±—ä–µ–¥–∏–Ω—è–µ–º)
            "cleanup_css.py": "frontend/optimize_css.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            "optimize_css.py": "frontend/optimize_css.py",  # –ë—É–¥–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω
            
            # Notifications - –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
            "send_daily_digests.py": "notifications/send_digests.py",  # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º
            
            # Testing - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            "test_advanced_parser.py": "testing/test_parser.py",  # –ü–µ—Ä–µ–∏–º–µ–Ω—É–µ–º
            
            # Utils - –£—Ç–∏–ª–∏—Ç—ã
            "repo_map.py": "utils/",
        }
        
    def create_backup(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
        print("üîÑ –°–æ–∑–¥–∞—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–∞–ø–∫–∏ tools...")
        self.backup_dir.mkdir(exist_ok=True)
        
        # –ö–æ–ø–∏—Ä—É–µ–º –ø–∞–ø–∫—É tools
        if (self.project_root / "tools").exists():
            shutil.copytree(self.project_root / "tools", self.backup_dir / "tools")
            print("  ‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –ø–∞–ø–∫–∞ tools")
        
        print(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞ –≤ {self.backup_dir}")
        
    def analyze_files(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ–º"""
        print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ñ–∞–π–ª—ã tools...")
        
        tools_files = list((self.project_root / "tools").glob("*.py"))
        
        print(f"  üìÅ –ù–∞–π–¥–µ–Ω–æ {len(tools_files)} —Ñ–∞–π–ª–æ–≤ –≤ tools")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–ø–ø–∏–Ω–≥
        unmapped_tools = []
        for file_path in tools_files:
            if file_path.name not in self.tools_mapping:
                unmapped_tools.append(file_path.name)
        
        if unmapped_tools:
            print(f"  ‚ö†Ô∏è –ù–µ –º–∞–ø–ø–∏—Ä–æ–≤–∞–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã: {unmapped_tools}")
        
        return unmapped_tools
        
    def create_new_structure(self):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫"""
        print("üìÅ –°–æ–∑–¥–∞—é –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫...")
        
        categories = [
            "management", "news", "events", "sources", 
            "ai", "frontend", "notifications", "testing", "utils"
        ]
        
        for category in categories:
            category_dir = self.tools_new / category
            category_dir.mkdir(parents=True, exist_ok=True)
            print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {category}/")
        
        print("‚úÖ –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ–∑–¥–∞–Ω–∞")
        
    def merge_similar_files(self):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã"""
        print("üîó –û–±—ä–µ–¥–∏–Ω—è—é –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã...")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º fetch —Ñ–∞–π–ª—ã
        fetch_files = [
            "fetch_and_store_news.py",
            "fetch_loop.py", 
            "fetch_optimized.py"
        ]
        
        merged_content = []
        merged_content.append('#!/usr/bin/env python3\n"""\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π.\n–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å fetch_and_store_news.py, fetch_loop.py, fetch_optimized.py\n"""\n')
        
        for file_name in fetch_files:
            file_path = self.project_root / "tools" / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                merged_content.append(f'\n# === –ò–ó {file_name} ===\n')
                merged_content.append(content)
                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω {file_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        merged_file = self.tools_new / "news" / "fetch_news.py"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª news/fetch_news.py")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º distribute —Ñ–∞–π–ª—ã
        distribute_files = [
            "distribute_sources.py",
            "smart_distribute_sources.py"
        ]
        
        merged_content = []
        merged_content.append('#!/usr/bin/env python3\n"""\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\n–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å distribute_sources.py, smart_distribute_sources.py\n"""\n')
        
        for file_name in distribute_files:
            file_path = self.project_root / "tools" / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                merged_content.append(f'\n# === –ò–ó {file_name} ===\n')
                merged_content.append(content)
                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω {file_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        merged_file = self.tools_new / "sources" / "distribute_sources.py"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª sources/distribute_sources.py")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º CSS —Ñ–∞–π–ª—ã
        css_files = [
            "cleanup_css.py",
            "optimize_css.py"
        ]
        
        merged_content = []
        merged_content.append('#!/usr/bin/env python3\n"""\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ CSS.\n–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å cleanup_css.py, optimize_css.py\n"""\n')
        
        for file_name in css_files:
            file_path = self.project_root / "tools" / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                merged_content.append(f'\n# === –ò–ó {file_name} ===\n')
                merged_content.append(content)
                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω {file_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        merged_file = self.tools_new / "frontend" / "optimize_css.py"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª frontend/optimize_css.py")
        
        print("‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
    def move_remaining_files(self):
        """–ü–µ—Ä–µ–º–µ—â–∞–µ—Ç –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ñ–∞–π–ª—ã –ø–æ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ"""
        print("üìÅ –ü–µ—Ä–µ–º–µ—â–∞—é –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ñ–∞–π–ª—ã...")
        
        moved_count = 0
        
        # –§–∞–π–ª—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è (–±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è)
        simple_moves = {
            "run_all.py": "management/",
            "port_manager.py": "management/",
            "load_fresh_news.py": "news/",
            "refresh_news.py": "news/",
            "clean_old_news.py": "news/",
            "merge_sources.py": "sources/",
            "repo_map.py": "utils/",
        }
        
        for filename, target_dir in simple_moves.items():
            src = self.project_root / "tools" / filename
            if src.exists():
                dst_dir = self.tools_new / target_dir
                dst_dir.mkdir(parents=True, exist_ok=True)
                dst = dst_dir / filename
                
                shutil.copy2(str(src), str(dst))
                print(f"  ‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω {filename} ‚Üí {target_dir}")
                moved_count += 1
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        renamed_files = {
            "update_news_with_universal_parser.py": ("news/", "update_news.py"),
            "fetch_and_store_events.py": ("events/", "fetch_events.py"),
            "build_baseline_dataset.py": ("ai/", "build_dataset.py"),
            "analyze_rejections.py": ("ai/", "analyze_data.py"),
            "send_daily_digests.py": ("notifications/", "send_digests.py"),
            "test_advanced_parser.py": ("testing/", "test_parser.py"),
        }
        
        for filename, (target_dir, new_name) in renamed_files.items():
            src = self.project_root / "tools" / filename
            if src.exists():
                dst_dir = self.tools_new / target_dir
                dst_dir.mkdir(parents=True, exist_ok=True)
                dst = dst_dir / new_name
                
                shutil.copy2(str(src), str(dst))
                print(f"  ‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω {filename} ‚Üí {target_dir}{new_name}")
                moved_count += 1
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º check —Ñ–∞–π–ª—ã
        check_files = ["check_all_sources.py", "check_templates.py"]
        merged_content = []
        merged_content.append('#!/usr/bin/env python3\n"""\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\n–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å check_all_sources.py, check_templates.py\n"""\n')
        
        for file_name in check_files:
            file_path = self.project_root / "tools" / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                merged_content.append(f'\n# === –ò–ó {file_name} ===\n')
                merged_content.append(content)
                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω {file_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        merged_file = self.tools_new / "sources" / "check_sources.py"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª sources/check_sources.py")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º validate —Ñ–∞–π–ª—ã
        validate_files = ["update_rss_sources.py", "validate_rss_sources.py"]
        merged_content = []
        merged_content.append('#!/usr/bin/env python3\n"""\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\n–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å update_rss_sources.py, validate_rss_sources.py\n"""\n')
        
        for file_name in validate_files:
            file_path = self.project_root / "tools" / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                merged_content.append(f'\n# === –ò–ó {file_name} ===\n')
                merged_content.append(content)
                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω {file_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        merged_file = self.tools_new / "sources" / "validate_sources.py"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª sources/validate_sources.py")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º AI —Ñ–∞–π–ª—ã
        ai_files = ["fill_ai_analysis_all.py", "train_self_tuning.py"]
        merged_content = []
        merged_content.append('#!/usr/bin/env python3\n"""\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.\n–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å fill_ai_analysis_all.py, train_self_tuning.py\n"""\n')
        
        for file_name in ai_files:
            file_path = self.project_root / "tools" / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                merged_content.append(f'\n# === –ò–ó {file_name} ===\n')
                merged_content.append(content)
                print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω {file_name}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        merged_file = self.tools_new / "ai" / "train_models.py"
        with open(merged_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(merged_content))
        print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª ai/train_models.py")
        
        print(f"‚úÖ –ü–µ—Ä–µ–º–µ—â–µ–Ω–æ {moved_count} —Ñ–∞–π–ª–æ–≤")
        
    def create_init_files(self):
        """–°–æ–∑–¥–∞–µ—Ç __init__.py —Ñ–∞–π–ª—ã –≤ –Ω–æ–≤—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö"""
        print("üìÑ –°–æ–∑–¥–∞—é __init__.py —Ñ–∞–π–ª—ã...")
        
        # –î–ª—è tools
        tool_dirs = [
            "management", "news", "events", "sources", 
            "ai", "frontend", "notifications", "testing", "utils"
        ]
        
        for dir_name in tool_dirs:
            init_file = self.tools_new / dir_name / "__init__.py"
            init_file.parent.mkdir(parents=True, exist_ok=True)
            init_file.write_text('"""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Å–∏—Å—Ç–µ–º–æ–π."""\n')
            print(f"  ‚úÖ –°–æ–∑–¥–∞–Ω {dir_name}/__init__.py")
        
        print("‚úÖ –í—Å–µ __init__.py —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã")
        
    def replace_old_with_new(self):
        """–ó–∞–º–µ–Ω—è–µ—Ç —Å—Ç–∞—Ä—É—é –ø–∞–ø–∫—É –Ω–æ–≤–æ–π"""
        print("üîÑ –ó–∞–º–µ–Ω—è—é —Å—Ç–∞—Ä—É—é –ø–∞–ø–∫—É –Ω–æ–≤–æ–π...")
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –ø–∞–ø–∫—É
        if (self.project_root / "tools").exists():
            shutil.rmtree(self.project_root / "tools")
            print("  ‚úÖ –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –ø–∞–ø–∫–∞ tools")
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É
        self.tools_new.rename(self.project_root / "tools")
        
        print("‚úÖ –ü–∞–ø–∫–∞ –∑–∞–º–µ–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
    def verify_structure(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
        print("üîç –ü—Ä–æ–≤–µ—Ä—è—é –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º tools
        tools_structure = {
            "management": 2,
            "news": 4,
            "events": 1,
            "sources": 4,
            "ai": 3,
            "frontend": 1,
            "notifications": 1,
            "testing": 1,
            "utils": 1,
        }
        
        for dir_name, expected_count in tools_structure.items():
            dir_path = self.project_root / "tools" / dir_name
            if dir_path.exists():
                file_count = len(list(dir_path.glob("*.py")))
                print(f"  ‚úÖ {dir_name}/ - {file_count} —Ñ–∞–π–ª–æ–≤ (–æ–∂–∏–¥–∞–ª–æ—Å—å {expected_count})")
            else:
                print(f"  ‚ùå {dir_name}/ - –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
    def optimize_structure(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        print("üßπ –ù–∞—á–∏–Ω–∞—é –∞–∫–∫—É—Ä–∞—Ç–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–∞–ø–∫–∏ tools...")
        print("=" * 60)
        
        try:
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
            self.create_backup()
            print()
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
            unmapped_tools = self.analyze_files()
            print()
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            self.create_new_structure()
            print()
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ñ–∞–π–ª—ã
            self.merge_similar_files()
            print()
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ñ–∞–π–ª—ã
            self.move_remaining_files()
            print()
            
            # –°–æ–∑–¥–∞–µ–º __init__.py —Ñ–∞–π–ª—ã
            self.create_init_files()
            print()
            
            # –ó–∞–º–µ–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –ø–∞–ø–∫—É –Ω–æ–≤–æ–π
            self.replace_old_with_new()
            print()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            self.verify_structure()
            
            print("\nüéâ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
            print("üí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
            print("  1. –û–±–Ω–æ–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç—ã –≤ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–∞—Ö")
            print("  2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è")
            print("  3. –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é")
            print("  4. –ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ git")
            
        except Exception as e:
            print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
            print("üîÑ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏...")
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            if self.backup_dir.exists():
                if (self.backup_dir / "tools").exists():
                    shutil.copytree(self.backup_dir / "tools", self.project_root / "tools")
                    print("  ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–∞–ø–∫–∞ tools")
                    
            print("‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

if __name__ == "__main__":
    optimizer = ToolsOptimizer()
    optimizer.optimize_structure()
