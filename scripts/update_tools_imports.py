#!/usr/bin/env python3
"""
üîß –°–∫—Ä–∏–ø—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–æ–≤ –ø–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ tools
–ê–≤—Ç–æ—Ä: AI Assistant
–í–µ—Ä—Å–∏—è: 1.0

–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–º–ø–æ—Ä—Ç—ã tools –≤ –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–∞—Ö –ø—Ä–æ–µ–∫—Ç–∞
"""

import os
import re
from pathlib import Path


class ToolsImportUpdater:
    def __init__(self, project_root="."):
        self.project_root = Path(project_root)

        # –ú–∞–ø–ø–∏–Ω–≥ —Å—Ç–∞—Ä—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤ –Ω–∞ –Ω–æ–≤—ã–µ
        self.import_mappings = {
            # Management –∏–º–ø–æ—Ä—Ç—ã
            "from tools.run_all": "from tools.management.run_all",
            "from tools.port_manager": "from tools.management.port_manager",
            "import tools.run_all": "import tools.management.run_all",
            "import tools.port_manager": "import tools.management.port_manager",
            # News –∏–º–ø–æ—Ä—Ç—ã
            "from tools.fetch_and_store_news": "from tools.news.fetch_news",
            "from tools.fetch_loop": "from tools.news.fetch_news",
            "from tools.fetch_optimized": "from tools.news.fetch_news",
            "from tools.load_fresh_news": "from tools.news.load_fresh_news",
            "from tools.refresh_news": "from tools.news.refresh_news",
            "from tools.clean_old_news": "from tools.news.clean_old_news",
            "from tools.update_news_with_universal_parser": "from tools.news.update_news",
            "import tools.fetch_and_store_news": "import tools.news.fetch_news",
            "import tools.fetch_loop": "import tools.news.fetch_news",
            "import tools.fetch_optimized": "import tools.news.fetch_news",
            "import tools.load_fresh_news": "import tools.news.load_fresh_news",
            "import tools.refresh_news": "import tools.news.refresh_news",
            "import tools.clean_old_news": "import tools.news.clean_old_news",
            "import tools.update_news_with_universal_parser": "import tools.news.update_news",
            # Events –∏–º–ø–æ—Ä—Ç—ã
            "from tools.fetch_and_store_events": "from tools.events.fetch_events",
            "import tools.fetch_and_store_events": "import tools.events.fetch_events",
            # Sources –∏–º–ø–æ—Ä—Ç—ã
            "from tools.check_all_sources": "from tools.sources.check_sources",
            "from tools.check_templates": "from tools.sources.check_sources",
            "from tools.distribute_sources": "from tools.sources.distribute_sources",
            "from tools.smart_distribute_sources": "from tools.sources.distribute_sources",
            "from tools.merge_sources": "from tools.sources.merge_sources",
            "from tools.update_rss_sources": "from tools.sources.validate_sources",
            "from tools.validate_rss_sources": "from tools.sources.validate_sources",
            "import tools.check_all_sources": "import tools.sources.check_sources",
            "import tools.check_templates": "import tools.sources.check_sources",
            "import tools.distribute_sources": "import tools.sources.distribute_sources",
            "import tools.smart_distribute_sources": "import tools.sources.distribute_sources",
            "import tools.merge_sources": "import tools.sources.merge_sources",
            "import tools.update_rss_sources": "import tools.sources.validate_sources",
            "import tools.validate_rss_sources": "import tools.sources.validate_sources",
            # AI –∏–º–ø–æ—Ä—Ç—ã
            "from tools.build_baseline_dataset": "from tools.ai.build_dataset",
            "from tools.fill_ai_analysis_all": "from tools.ai.train_models",
            "from tools.train_self_tuning": "from tools.ai.train_models",
            "from tools.analyze_rejections": "from tools.ai.analyze_data",
            "import tools.build_baseline_dataset": "import tools.ai.build_dataset",
            "import tools.fill_ai_analysis_all": "import tools.ai.train_models",
            "import tools.train_self_tuning": "import tools.ai.train_models",
            "import tools.analyze_rejections": "import tools.ai.analyze_data",
            # Frontend –∏–º–ø–æ—Ä—Ç—ã
            "from tools.cleanup_css": "from tools.frontend.optimize_css",
            "from tools.optimize_css": "from tools.frontend.optimize_css",
            "import tools.cleanup_css": "import tools.frontend.optimize_css",
            "import tools.optimize_css": "import tools.frontend.optimize_css",
            # Notifications –∏–º–ø–æ—Ä—Ç—ã
            "from tools.send_daily_digests": "from tools.notifications.send_digests",
            "import tools.send_daily_digests": "import tools.notifications.send_digests",
            # Testing –∏–º–ø–æ—Ä—Ç—ã
            "from tools.test_advanced_parser": "from tools.testing.test_parser",
            "import tools.test_advanced_parser": "import tools.testing.test_parser",
            # Utils –∏–º–ø–æ—Ä—Ç—ã
            "from tools.repo_map": "from tools.utils.repo_map",
            "import tools.repo_map": "import tools.utils.repo_map",
        }

    def update_file_imports(self, file_path):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–º–ø–æ—Ä—Ç—ã –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()

            original_content = content
            updated_count = 0

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Å–µ –º–∞–ø–ø–∏–Ω–≥–∏
            for old_import, new_import in self.import_mappings.items():
                if old_import in content:
                    content = content.replace(old_import, new_import)
                    updated_count += 1

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –µ—Å–ª–∏ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            if content != original_content:
                with open(file_path, "w", encoding="utf-8") as f:
                    f.write(content)
                return updated_count

            return 0

        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ {file_path}: {e}")
            return 0

    def update_all_imports(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ"""
        print("üîß –ù–∞—á–∏–Ω–∞—é –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤ tools...")
        print("=" * 50)

        total_files = 0
        total_updates = 0

        # –ò—â–µ–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å tools
        search_paths = [
            "ai_modules",
            "database",
            "digests",
            "events",
            "parsers",
            "repositories",
            "routes",
            "services",
            "telegram_bot",
            "tests",
            "utils",
        ]

        for search_path in search_paths:
            path = self.project_root / search_path
            if path.exists():
                for py_file in path.glob("**/*.py"):
                    total_files += 1
                    updates = self.update_file_imports(py_file)
                    if updates > 0:
                        print(f"  ‚úÖ {py_file.relative_to(self.project_root)} - {updates} –∏–º–ø–æ—Ä—Ç–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ")
                        total_updates += updates

        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ
        for py_file in self.project_root.glob("*.py"):
            total_files += 1
            updates = self.update_file_imports(py_file)
            if updates > 0:
                print(f"  ‚úÖ {py_file.name} - {updates} –∏–º–ø–æ—Ä—Ç–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ")
                total_updates += updates

        print(f"\nüéâ –û–ë–ù–û–í–õ–ï–ù–ò–ï –ò–ú–ü–û–†–¢–û–í –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"üìä –í—Å–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {total_updates} –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ {total_files} —Ñ–∞–π–ª–∞—Ö")

        return total_updates

    def verify_imports(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤—Å–µ –∏–º–ø–æ—Ä—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã"""
        print("üîç –ü—Ä–æ–≤–µ—Ä—è—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏–º–ø–æ—Ä—Ç–æ–≤...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
        test_files = ["scripts/start_services.sh", "scripts/stop_services.sh", "Makefile"]

        for test_file in test_files:
            file_path = self.project_root / test_file
            if file_path.exists():
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã –∑–∞–º–µ–Ω–µ–Ω—ã
                old_imports = [imp for imp in self.import_mappings.keys() if imp in content]
                if old_imports:
                    print(f"  ‚ö†Ô∏è {test_file} –≤—Å–µ –µ—â–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Å—Ç–∞—Ä—ã–µ –∏–º–ø–æ—Ä—Ç—ã: {old_imports}")
                else:
                    print(f"  ‚úÖ {test_file} - –∏–º–ø–æ—Ä—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã")

        print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


if __name__ == "__main__":
    updater = ToolsImportUpdater()
    updater.update_all_imports()
    updater.verify_imports()
